{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#우리의 mnist 해결 mechanism\n",
    "\n",
    "\n",
    "#train data를 이용해서 해당 모델을 학습\n",
    "#결국 얻을려는건 H 하이파시스\n",
    "\n",
    "#H를 얻어내서 이걸 이용해서 예측(predict)가 가능 \n",
    "\n",
    "##test data(입력 feature ) 가 들어감\n",
    "\n",
    "#소프트맥스 취하면 \n",
    "\n",
    "#H->[0.12,0.02,0.33,0.122,0.34]\n",
    "\n",
    "# argmax가장큰값을 찾아내는것 index를 얻고\n",
    "\n",
    "#이값을 입력 label의 argmax와 비교해서 잘맞으면 예측이 잘되었다 \n",
    "\n",
    "#결국 랜덤값으로 실행하는거라 운에 좌지우지\n",
    "\n",
    "#그래서 결국 여러모델을 만들어서 결과를 취합\n",
    "\n",
    "\n",
    "\n",
    "#### 앙상블\n",
    "\n",
    "#기법으로 모델을 여러개만듬 리스트던 배열이던\n",
    "\n",
    "#각각의 모델을 학습 \n",
    "#각 모델에 입력 parameter(이미지 픽셀) 을 넣어서 예측값 알아냄\n",
    "#model 1 -> [0.1,0.4]\n",
    "#model 2 -> [0.2,0.5]\n",
    "#..\n",
    "#model 10\n",
    "\n",
    "#각 열을 더함\n",
    "\n",
    "\n",
    "#그래서 클레스와 인스턴스를 이용\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0b1fa75e149c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mstu2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStudent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"김길동\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstu2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_avg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Student:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,kor,eng,math):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.kor=kor\n",
    "        self.eng=eng\n",
    "        self.math=math\n",
    "    \n",
    "    def calc_avg(self):\n",
    "        return (self.kor+self.eng+self.math)/3\n",
    "stu1=Student(\"홍길동\",10,20,30)\n",
    "print(stu1.calc_avg())\n",
    "\n",
    "stu2=Student(\"김길동\",10,20,30)\n",
    "print(stu2.calc_avg())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "class cnnmodel:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,sess):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.sess=sess\n",
    "    def cost(self,train1,df4):\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        for step in range(10):\n",
    "            num_of_iter = 42000\n",
    "\n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "\n",
    "\n",
    "                batch_x = train1[n:n2]\n",
    "                batch_y = df4[n:n2]\n",
    "                _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "\n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "    def study(train1,train2):\n",
    "        df1=pd.DataFrame()\n",
    "        df2=pd.DataFrame()\n",
    "        df4=pd.DataFrame()\n",
    "\n",
    "        arr = np.zeros((10,10), dtype=np.int32)\n",
    "        df1=arr\n",
    "\n",
    "        for n in range(0,10):\n",
    "\n",
    "            df1[n,n]=1\n",
    "            df2[n]=np.arange(10)\n",
    "\n",
    "        tr2=int(len(train2))\n",
    "\n",
    "\n",
    "        for n in range(0,tr2):\n",
    "\n",
    "            df2[n]=df1[train2[n]]\n",
    "\n",
    "        df4=df2.transpose()\n",
    "\n",
    "        number=int(len(train1)*2/3)\n",
    "\n",
    "\n",
    "        train1_1=train1[0:number]\n",
    "        train1_test=train1[number:-1]\n",
    "\n",
    "        df4_1=df4[0:number]\n",
    "        df4_test=df4[number:-1]\n",
    "\n",
    "\n",
    "        X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "        W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "        L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "        L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "        L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "        L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "        W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "        _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "        layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "        W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "        _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "        layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "        H = tf.matmul(layer2,W4)+b4\n",
    "        \n",
    "        cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "        train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "        sess=tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        return H\n",
    "    \n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class cnnmodel:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,kor,eng,math):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.kor=kor\n",
    "        self.eng=eng\n",
    "        self.math=math\n",
    "    \n",
    "    def create_network(self)\n",
    "        return (self.kor+self.eng+self.math)/3\n",
    "stu1=Student(\"홍길동\",10,20,30)\n",
    "print(stu1.calc_avg())\n",
    "\n",
    "stu2=Student(\"김길동\",10,20,30)\n",
    "print(stu2.calc_avg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27972</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27974</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27975</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27976</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27978</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27979</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27982</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27983</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27984</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27986</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9\n",
       "0      0  1  0  0  0  0  0  0  0  0\n",
       "1      1  0  0  0  0  0  0  0  0  0\n",
       "2      0  1  0  0  0  0  0  0  0  0\n",
       "3      0  0  0  0  1  0  0  0  0  0\n",
       "4      1  0  0  0  0  0  0  0  0  0\n",
       "5      1  0  0  0  0  0  0  0  0  0\n",
       "6      0  0  0  0  0  0  0  1  0  0\n",
       "7      0  0  0  1  0  0  0  0  0  0\n",
       "8      0  0  0  0  0  1  0  0  0  0\n",
       "9      0  0  0  1  0  0  0  0  0  0\n",
       "10     0  0  0  0  0  0  0  0  1  0\n",
       "11     0  0  0  0  0  0  0  0  0  1\n",
       "12     0  1  0  0  0  0  0  0  0  0\n",
       "13     0  0  0  1  0  0  0  0  0  0\n",
       "14     0  0  0  1  0  0  0  0  0  0\n",
       "15     0  1  0  0  0  0  0  0  0  0\n",
       "16     0  0  1  0  0  0  0  0  0  0\n",
       "17     1  0  0  0  0  0  0  0  0  0\n",
       "18     0  0  0  0  0  0  0  1  0  0\n",
       "19     0  0  0  0  0  1  0  0  0  0\n",
       "20     0  0  0  0  0  0  0  0  1  0\n",
       "21     0  0  0  0  0  0  1  0  0  0\n",
       "22     0  0  1  0  0  0  0  0  0  0\n",
       "23     1  0  0  0  0  0  0  0  0  0\n",
       "24     0  0  1  0  0  0  0  0  0  0\n",
       "25     0  0  0  1  0  0  0  0  0  0\n",
       "26     0  0  0  0  0  0  1  0  0  0\n",
       "27     0  0  0  0  0  0  0  0  0  1\n",
       "28     0  0  0  0  0  0  0  0  0  1\n",
       "29     0  0  0  0  0  0  0  1  0  0\n",
       "...   .. .. .. .. .. .. .. .. .. ..\n",
       "27970  0  0  1  0  0  0  0  0  0  0\n",
       "27971  0  0  1  0  0  0  0  0  0  0\n",
       "27972  1  0  0  0  0  0  0  0  0  0\n",
       "27973  0  0  0  0  1  0  0  0  0  0\n",
       "27974  1  0  0  0  0  0  0  0  0  0\n",
       "27975  0  1  0  0  0  0  0  0  0  0\n",
       "27976  1  0  0  0  0  0  0  0  0  0\n",
       "27977  0  0  0  0  0  0  1  0  0  0\n",
       "27978  0  1  0  0  0  0  0  0  0  0\n",
       "27979  1  0  0  0  0  0  0  0  0  0\n",
       "27980  0  0  0  0  0  0  0  0  0  1\n",
       "27981  0  0  0  0  0  0  0  0  1  0\n",
       "27982  0  1  0  0  0  0  0  0  0  0\n",
       "27983  1  0  0  0  0  0  0  0  0  0\n",
       "27984  0  1  0  0  0  0  0  0  0  0\n",
       "27985  0  0  0  0  0  0  0  0  1  0\n",
       "27986  1  0  0  0  0  0  0  0  0  0\n",
       "27987  0  0  0  0  0  0  0  0  0  1\n",
       "27988  0  0  1  0  0  0  0  0  0  0\n",
       "27989  0  0  0  0  0  0  0  0  1  0\n",
       "27990  0  0  0  0  0  0  1  0  0  0\n",
       "27991  0  0  0  0  0  0  0  1  0  0\n",
       "27992  0  0  0  0  0  0  1  0  0  0\n",
       "27993  0  0  0  1  0  0  0  0  0  0\n",
       "27994  0  0  0  0  0  0  1  0  0  0\n",
       "27995  0  0  0  0  0  0  1  0  0  0\n",
       "27996  1  0  0  0  0  0  0  0  0  0\n",
       "27997  0  0  0  0  0  0  0  0  1  0\n",
       "27998  1  0  0  0  0  0  0  0  0  0\n",
       "27999  0  0  0  0  0  0  0  1  0  0\n",
       "\n",
       "[28000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "class cnnmodel:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,sess):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.sess=sess\n",
    "        \n",
    "    def onehot(self):\n",
    "        df1=pd.DataFrame()\n",
    "        df2=pd.DataFrame()\n",
    "        df4=pd.DataFrame()\n",
    "        \n",
    "        arr = np.zeros((10,10), dtype=np.int32)\n",
    "        df1=arr\n",
    "        \n",
    "        for n in range(0,10):\n",
    "            df1[n,n]=1\n",
    "            df2[n]=np.arange(10)\n",
    "\n",
    "        tr2=int(len(train2))\n",
    "\n",
    "\n",
    "        for n in range(0,tr2):\n",
    "            df2[n]=df1[train2[n]]\n",
    "\n",
    "        df4=df2.transpose()\n",
    "        return df4\n",
    "    def train_test(self,train1,df4):\n",
    "    \n",
    "        number=int(len(train1)*2/3)\n",
    "\n",
    "        train1_1=train1[0:number]\n",
    "        train1_test=train1[number:-1]\n",
    "\n",
    "        df4_1=df4[0:number]\n",
    "        df4_test=df4[number:-1]\n",
    "        \n",
    "        return df4_1 # , , , \n",
    "        \n",
    "    def Layer1(self):\n",
    "    \n",
    "        X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "        W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "        L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "        L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "        L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "        L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "        \n",
    "        return L2\n",
    "    \n",
    "    \n",
    "    def wbh(self):\n",
    "\n",
    "        W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "        _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "        layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "        _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "        layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "        H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "        return H\n",
    "    \n",
    "\n",
    "# cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "# train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# sess=tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# n=0\n",
    "# n1=100\n",
    "# n2=100\n",
    "\n",
    "# print(int(nn))\n",
    "\n",
    "# for step in range(10):\n",
    "#     num_of_iter = 42000\n",
    "    \n",
    "#     n=0\n",
    "#     n1=100\n",
    "#     n2=100\n",
    "    \n",
    "#     for i in range(420):\n",
    "        \n",
    "        \n",
    "#         batch_x = train1[n:n2]\n",
    "#         batch_y = df4[n:n2]\n",
    "#         _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "#         n=n+n1\n",
    "#         n2=n2+n1\n",
    "        \n",
    "#     print(\"cost : {}\".format(cost_val))\n",
    "    \n",
    "\n",
    "# predict = tf.argmax(H,1)\n",
    "# correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "# accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "# yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "  \n",
    "    \n",
    "    \n",
    "    def Label(self):\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        a=[]\n",
    "\n",
    "        for i in range(280):\n",
    "            batch_x=test[n:n2]\n",
    "\n",
    "            #yy_value.loc[n:n2,\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "            a.extend(sess.run(predict, feed_dict={X:batch_x,keep_rate:1}))\n",
    "            \n",
    "\n",
    "        yy_value[\"Label\"]=a\n",
    "        \n",
    "        return yy_value\n",
    "    def image(self):\n",
    "\n",
    "        nnn=[]\n",
    "        for nnnn in range(1,28001):\n",
    "            nnn.append(nnnn)\n",
    "\n",
    "        yy_value[\"ImageId\"]=nnn\n",
    "        print(yy_value)\n",
    "\n",
    "        return yy_value\n",
    "    \n",
    "    def save(self):\n",
    "        yy_value.to_csv(\"./data/submit_mnist\", index=False)\n",
    "\n",
    "    def testdata(self):\n",
    "    \n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        for i in range(140):\n",
    "            batch_x=train1_test[n:n2]\n",
    "            batch_y =df4_test[n:n2]\n",
    "            correct_num=sess.run(accuracy, feed_dict={X:batch_x , Y:batch_y ,keep_rate:1})\n",
    "            result_sum += correct_num\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "        \n",
    "        print(\"정확도:{}\".format(result_sum/14000))\n",
    "    \n",
    "#for n in range(10)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "cnn=cnnmodel(\"model\",sess)\n",
    "    \n",
    "#display(cnn.train_test(train1,cnn.onehot()))\n",
    "\n",
    "display(cnn.train_test(train1,cnn.onehot()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "nn=int(len(train1))\n",
    "\n",
    "X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "keep_rate=tf.placeholder(dtype=tf.float32)  #드랍아웃에서 얼마나 살릴지\n",
    "\n",
    "\n",
    "df1=pd.DataFrame()\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "df1=arr\n",
    "\n",
    "df2=pd.DataFrame()\n",
    "\n",
    "\n",
    "for n in range(0,10):\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "\n",
    "\n",
    "for n in range(0,tr2):\n",
    "    df2[n]=df1[train2[n]]\n",
    "\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "df4=df2.transpose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "number=int(len(train1)*2/3)\n",
    "\n",
    "train1_1=train1[0:number]\n",
    "train1_test=train1[number:-1]\n",
    "\n",
    "df4_1=df4[0:number]\n",
    "df4_test=df4[number:-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "\n",
    "L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "#########CONVOLUTION LAYER 끝\n",
    "\n",
    "#4. NURAL NETWORK\n",
    "\n",
    "L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "#print(L2.shape)\n",
    "\n",
    "# 5. weight & bias\n",
    "\n",
    "W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "\n",
    "# hypothesis 가설만들어야함\n",
    "\n",
    "\n",
    "H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "#cost 함수\n",
    "\n",
    "cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "\n",
    "num_of_epoch = 10\n",
    "batch_size=100\n",
    "\n",
    "display(train1)\n",
    "display(df4)\n",
    "\n",
    "\n",
    "n=0\n",
    "n1=100\n",
    "n2=100\n",
    "\n",
    "print(int(nn))\n",
    "for step in range(10):\n",
    "    num_of_iter = 42000\n",
    "    \n",
    "    n=0\n",
    "    n1=100\n",
    "    n2=100\n",
    "    \n",
    "    for i in range(420):\n",
    "        \n",
    "        \n",
    "        batch_x = train1[n:n2]\n",
    "        batch_y = df4[n:n2]\n",
    "        _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "        n=n+n1\n",
    "        n2=n2+n1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"cost : {}\".format(cost_val))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "result_sum=0\n",
    "num_of_iter = int(num_of_iter/100)\n",
    "\n",
    "\n",
    "\n",
    "### 라벨 뽑기 predict 이용\n",
    "yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "\n",
    "n=0\n",
    "n1=100\n",
    "n2=100\n",
    "\n",
    "for i in range(280):\n",
    "    batch_x=test[n:n2]\n",
    "    \n",
    "    yy_value[\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "    \n",
    "    n=n+n1\n",
    "    n2=n2+n1\n",
    "\n",
    "print(yy_value)\n",
    "print(\"=========\")\n",
    "\n",
    "\n",
    "n=0\n",
    "n1=100\n",
    "n2=100\n",
    "a=[]\n",
    "\n",
    "for i in range(280):\n",
    "    batch_x=test[n:n2]\n",
    "    \n",
    "    #yy_value.loc[n:n2,\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "    a.extend(sess.run(predict, feed_dict={X:batch_x,keep_rate:1}))\n",
    "    \n",
    "\n",
    "print(\"=========\")\n",
    "\n",
    "yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "yy_value[\"Label\"]=a\n",
    "\n",
    "nnn=[]\n",
    "for nnnn in range(1,28001):\n",
    "    nnn.append(nnnn)\n",
    "\n",
    "yy_value[\"ImageId\"]=nnn\n",
    "print(yy_value)\n",
    "\n",
    "\n",
    "yy_value.to_csv(\"./data/submit_mnist\", index=False)\n",
    "\n",
    "\n",
    "###테스트\n",
    "\n",
    "# yy_value=sess.run(predict , feed_dict={X:test,keep_rate:1})\n",
    "\n",
    "# dfff=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "# dfff[\"label\"]=yy_value\n",
    "# arr=[]\n",
    "# for dfffnum in range(0,len(dfff)):\n",
    "#     arr=dfffnum\n",
    "\n",
    "# print(dfffnum)\n",
    "\n",
    "\n",
    "\n",
    "#=================\n",
    "\n",
    "\n",
    "# n=0\n",
    "# n1=100\n",
    "# n2=100\n",
    "# for i in range(140):\n",
    "#     batch_x=train1_test[n:n2]\n",
    "#     batch_y =df4_test[n:n2]\n",
    "#     correct_num=sess.run(accuracy, feed_dict={X:batch_x , Y:batch_y ,keep_rate:1})\n",
    "#     result_sum += correct_num\n",
    "#     n=n+n1\n",
    "#     n2=n2+n1\n",
    "    \n",
    "    \n",
    "# #tf.cast(correct , dtype=tf.float32# 맞으면 1 틀리면 0 100개를 끌어왔는데 반은맞고 반은 틀리면 50이됨 \n",
    "# #print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images,Y:mnist.test.labels,keep_rate:1})) )\n",
    "\n",
    "# print(\"정확도:{}\".format(result_sum/14000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "class cnnmodel:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,sess):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.sess=sess\n",
    "        \n",
    "    def onehot(self):\n",
    "        df1=pd.DataFrame()\n",
    "        df2=pd.DataFrame()\n",
    "        df4=pd.DataFrame()\n",
    "        \n",
    "        arr = np.zeros((10,10), dtype=np.int32)\n",
    "        df1=arr\n",
    "        \n",
    "        for n in range(0,10):\n",
    "            df1[n,n]=1\n",
    "            df2[n]=np.arange(10)\n",
    "\n",
    "        tr2=int(len(train2))\n",
    "\n",
    "\n",
    "        for n in range(0,tr2):\n",
    "            df2[n]=df1[train2[n]]\n",
    "\n",
    "        df4=df2.transpose()\n",
    "        return df4\n",
    "    def train_test(self,train1,df4):\n",
    "    \n",
    "        number=int(len(train1)*2/3)\n",
    "\n",
    "        train1_1=train1[0:number]\n",
    "        train1_test=train1[number:-1]\n",
    "\n",
    "        df4_1=df4[0:number]\n",
    "        df4_test=df4[number:-1]\n",
    "        \n",
    "        return df4_1 # , , , \n",
    "        \n",
    "    def Layer1(self):\n",
    "    \n",
    "        X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "        W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "        L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "        L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "        L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "        L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "        \n",
    "        return L2\n",
    "    \n",
    "    \n",
    "    def wbh(self):\n",
    "\n",
    "        W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "        _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "        layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "        _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "        layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "        H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "        return H\n",
    "    \n",
    "\n",
    "# cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "# train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# sess=tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# n=0\n",
    "# n1=100\n",
    "# n2=100\n",
    "\n",
    "# print(int(nn))\n",
    "\n",
    "# for step in range(10):\n",
    "#     num_of_iter = 42000\n",
    "    \n",
    "#     n=0\n",
    "#     n1=100\n",
    "#     n2=100\n",
    "    \n",
    "#     for i in range(420):\n",
    "        \n",
    "        \n",
    "#         batch_x = train1[n:n2]\n",
    "#         batch_y = df4[n:n2]\n",
    "#         _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "#         n=n+n1\n",
    "#         n2=n2+n1\n",
    "        \n",
    "#     print(\"cost : {}\".format(cost_val))\n",
    "    \n",
    "\n",
    "# predict = tf.argmax(H,1)\n",
    "# correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "# accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "# yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "  \n",
    "    \n",
    "    \n",
    "    def Label(self):\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        a=[]\n",
    "\n",
    "        for i in range(280):\n",
    "            batch_x=test[n:n2]\n",
    "\n",
    "            #yy_value.loc[n:n2,\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "            a.extend(sess.run(predict, feed_dict={X:batch_x,keep_rate:1}))\n",
    "            \n",
    "\n",
    "        yy_value[\"Label\"]=a\n",
    "        \n",
    "        return yy_value\n",
    "    def image(self):\n",
    "\n",
    "        nnn=[]\n",
    "        for nnnn in range(1,28001):\n",
    "            nnn.append(nnnn)\n",
    "\n",
    "        yy_value[\"ImageId\"]=nnn\n",
    "        print(yy_value)\n",
    "\n",
    "        return yy_value\n",
    "    \n",
    "    def save(self):\n",
    "        yy_value.to_csv(\"./data/submit_mnist\", index=False)\n",
    "\n",
    "    def testdata(self):\n",
    "    \n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        for i in range(140):\n",
    "            batch_x=train1_test[n:n2]\n",
    "            batch_y =df4_test[n:n2]\n",
    "            correct_num=sess.run(accuracy, feed_dict={X:batch_x , Y:batch_y ,keep_rate:1})\n",
    "            result_sum += correct_num\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "        \n",
    "        print(\"정확도:{}\".format(result_sum/14000))\n",
    "    \n",
    "#for n in range(10)\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "cnn=cnnmodel(\"model\",sess)\n",
    "    \n",
    "#display(cnn.train_test(train1,cnn.onehot()))\n",
    "\n",
    "display(cnn.train_test(train1,cnn.onehot()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "\n",
    "class cnnmodel:   \n",
    "    def __init__(self,name,sess):  \n",
    "\n",
    "        self.name=name  \n",
    "        self.sess=sess\n",
    "        \n",
    "    def model(self):\n",
    "        nn=int(len(train1))\n",
    "\n",
    "        X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "        Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "        keep_rate=tf.placeholder(dtype=tf.float32)  #드랍아웃에서 얼마나 살릴지\n",
    "\n",
    "\n",
    "        df1=pd.DataFrame()\n",
    "        arr = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "        df1=arr\n",
    "\n",
    "        df2=pd.DataFrame()\n",
    "\n",
    "\n",
    "        for n in range(0,10):\n",
    "            df1[n,n]=1\n",
    "            df2[n]=np.arange(10)\n",
    "\n",
    "        tr2=int(len(train2))\n",
    "\n",
    "\n",
    "        for n in range(0,tr2):\n",
    "            df2[n]=df1[train2[n]]\n",
    "\n",
    "        df4=pd.DataFrame()\n",
    "\n",
    "        df4=df2.transpose()\n",
    "\n",
    "\n",
    "        number=int(len(train1)*2/3)\n",
    "\n",
    "        train1_1=train1[0:number]\n",
    "        train1_test=train1[number:-1]\n",
    "\n",
    "        df4_1=df4[0:number]\n",
    "        df4_test=df4[number:-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "        W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "        L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "        L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "\n",
    "        L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "        #########CONVOLUTION LAYER 끝\n",
    "\n",
    "        #4. NURAL NETWORK\n",
    "\n",
    "        L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "        #print(L2.shape)\n",
    "\n",
    "        # 5. weight & bias\n",
    "\n",
    "        W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "        _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "        layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "        _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "        layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "\n",
    "        # hypothesis 가설만들어야함\n",
    "\n",
    "\n",
    "        H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "        #cost 함수\n",
    "\n",
    "        cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "        train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "        sess=tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #학습\n",
    "\n",
    "        num_of_epoch = 10\n",
    "        batch_size=100\n",
    "\n",
    "        display(train1)\n",
    "        display(df4)\n",
    "\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "\n",
    "        print(int(nn))\n",
    "        for step in range(10):\n",
    "            num_of_iter = 42000\n",
    "\n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "\n",
    "\n",
    "                batch_x = train1[n:n2]\n",
    "                batch_y = df4[n:n2]\n",
    "                _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        predict = tf.argmax(H,1)\n",
    "        correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "        accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "        result_sum=0\n",
    "        num_of_iter = int(num_of_iter/100)\n",
    "\n",
    "\n",
    "\n",
    "        ### 라벨 뽑기 predict 이용\n",
    "        yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "\n",
    "        for i in range(280):\n",
    "            batch_x=test[n:n2]\n",
    "\n",
    "            yy_value[\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "\n",
    "        print(yy_value)\n",
    "        print(\"=========\")\n",
    "\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        a=[]\n",
    "\n",
    "        for i in range(280):\n",
    "            batch_x=test[n:n2]\n",
    "\n",
    "            #yy_value.loc[n:n2,\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "            a.extend(sess.run(predict, feed_dict={X:batch_x,keep_rate:1}))\n",
    "\n",
    "\n",
    "        print(\"=========\")\n",
    "\n",
    "        yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "        yy_value[\"Label\"]=a\n",
    "\n",
    "        nnn=[]\n",
    "        for nnnn in range(1,28001):\n",
    "            nnn.append(nnnn)\n",
    "\n",
    "        yy_value[\"ImageId\"]=nnn\n",
    "        print(yy_value)\n",
    "\n",
    "\n",
    "        yy_value.to_csv(\"./data/submit_mnist\", index=False)\n",
    "\n",
    "\n",
    "        ###테스트\n",
    "\n",
    "        # yy_value=sess.run(predict , feed_dict={X:test,keep_rate:1})\n",
    "\n",
    "        # dfff=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "        # dfff[\"label\"]=yy_value\n",
    "        # arr=[]\n",
    "        # for dfffnum in range(0,len(dfff)):\n",
    "        #     arr=dfffnum\n",
    "\n",
    "        # print(dfffnum)\n",
    "\n",
    "\n",
    "\n",
    "        #=================\n",
    "\n",
    "\n",
    "        # n=0\n",
    "        # n1=100\n",
    "        # n2=100\n",
    "        # for i in range(140):\n",
    "        #     batch_x=train1_test[n:n2]\n",
    "        #     batch_y =df4_test[n:n2]\n",
    "        #     correct_num=sess.run(accuracy, feed_dict={X:batch_x , Y:batch_y ,keep_rate:1})\n",
    "        #     result_sum += correct_num\n",
    "        #     n=n+n1\n",
    "        #     n2=n2+n1\n",
    "\n",
    "\n",
    "        # #tf.cast(correct , dtype=tf.float32# 맞으면 1 틀리면 0 100개를 끌어왔는데 반은맞고 반은 틀리면 50이됨 \n",
    "        # #print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images,Y:mnist.test.labels,keep_rate:1})) )\n",
    "\n",
    "        # print(\"정확도:{}\".format(result_sum/14000))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "stu1=Student(\"홍길동\",10,20,30)\n",
    "print(stu1.calc_avg())\n",
    "\n",
    "stu2=Student(\"김길동\",10,20,30)\n",
    "print(stu2.calc_avg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 0.3071288466453552\n",
      "cost : 0.3279969096183777\n",
      "cost : 0.18736927211284637\n",
      "cost : 0.18291230499744415\n",
      "cost : 0.160679429769516\n",
      "cost : 0.3759686350822449\n",
      "cost : 0.2836356461048126\n",
      "cost : 0.1708727478981018\n",
      "cost : 0.2695407271385193\n",
      "cost : 0.18917755782604218\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'Sum:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Sum:0\", shape=(), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 300\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    301\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3489\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3490\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3568\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3569\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3570\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"Sum:0\", shape=(), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-babd997d37d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcnnmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m \u001b[0myyy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myyy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-babd997d37d6>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[0myyy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1137\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \"\"\"\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    305\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 307\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    308\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'Sum:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"Sum:0\", shape=(), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "\n",
    "class cnnmodel:   \n",
    "    def __init__(self,name):  \n",
    "\n",
    "        self.name=name  \n",
    "       \n",
    "        \n",
    "    def model(self):\n",
    "        nn=int(len(train1))\n",
    "\n",
    "        X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "        Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "        keep_rate=tf.placeholder(dtype=tf.float32)  #드랍아웃에서 얼마나 살릴지\n",
    "\n",
    "\n",
    "        df1=pd.DataFrame()\n",
    "        arr = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "        df1=arr\n",
    "\n",
    "        df2=pd.DataFrame()\n",
    "\n",
    "\n",
    "        for n in range(0,10):\n",
    "            df1[n,n]=1\n",
    "            df2[n]=np.arange(10)\n",
    "\n",
    "        tr2=int(len(train2))\n",
    "\n",
    "\n",
    "        for n in range(0,tr2):\n",
    "            df2[n]=df1[train2[n]]\n",
    "\n",
    "        df4=pd.DataFrame()\n",
    "\n",
    "        df4=df2.transpose()\n",
    "\n",
    "\n",
    "        number=int(len(train1)*2/3)\n",
    "\n",
    "        train1_1=train1[0:number]\n",
    "        train1_test=train1[number:-1]\n",
    "\n",
    "        df4_1=df4[0:number]\n",
    "        df4_test=df4[number:-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "        W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "        L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "        L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "\n",
    "\n",
    "        L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "        #########CONVOLUTION LAYER 끝\n",
    "\n",
    "        #4. NURAL NETWORK\n",
    "\n",
    "        L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "        #print(L2.shape)\n",
    "\n",
    "        # 5. weight & bias\n",
    "\n",
    "        W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "        _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "        layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "        _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "        layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "\n",
    "        # hypothesis 가설만들어야함\n",
    "\n",
    "\n",
    "        H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "        #cost 함수\n",
    "\n",
    "        cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "        train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "        sess=tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        #학습\n",
    "\n",
    "        num_of_epoch = 10\n",
    "        batch_size=100\n",
    "\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "\n",
    "        \n",
    "        for step in range(10):\n",
    "            num_of_iter = 42000\n",
    "\n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "\n",
    "\n",
    "                batch_x = train1[n:n2]\n",
    "                batch_y = df4[n:n2]\n",
    "                _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        predict = tf.argmax(H,1)\n",
    "        correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "        accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "        \n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        y=[]\n",
    "        for i in range(420):\n",
    "\n",
    "            batch_x=test[n:n2]\n",
    "\n",
    "            yyy=sess.run(ac, feed_dict={X:batch_x,keep_rate:1})\n",
    "\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "\n",
    "        print(yyy)\n",
    "        \n",
    "        return yyy\n",
    "\n",
    "    \n",
    "cnn=cnnmodel(\"model1\")\n",
    "yyy=cnn.model()\n",
    "print(yyy)\n",
    "\n",
    "\n",
    "          #### 샘플데이터 양식 만들기\n",
    "        ### 라벨 뽑기 predict 이용\n",
    "#         yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "\n",
    "#         n=0\n",
    "#         n1=100\n",
    "#         n2=100\n",
    "\n",
    "#         for i in range(280):\n",
    "#             batch_x=test[n:n2]\n",
    "\n",
    "#             yy_value[\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "\n",
    "#             n=n+n1\n",
    "#             n2=n2+n1\n",
    "\n",
    "#         print(yy_value)\n",
    "#         print(\"=========\")\n",
    "\n",
    "     \n",
    "        \n",
    "        \n",
    "#         n=0\n",
    "#         n1=100\n",
    "#         n2=100\n",
    "#         a=[]\n",
    "\n",
    "#         for i in range(280):\n",
    "#             batch_x=test[n:n2]\n",
    "\n",
    "#             #yy_value.loc[n:n2,\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "#             a.extend(sess.run(predict, feed_dict={X:batch_x,keep_rate:1}))\n",
    "\n",
    "\n",
    "#         print(\"=========\")\n",
    "\n",
    "#         yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "#         yy_value[\"Label\"]=a\n",
    "\n",
    "#         nnn=[]\n",
    "#         for nnnn in range(1,28001):\n",
    "#             nnn.append(nnnn)\n",
    "\n",
    "#         yy_value[\"ImageId\"]=nnn\n",
    "#         print(yy_value)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ###저장\n",
    "        #yy_value.to_csv(\"./data/submit_mnist\", index=False)\n",
    "\n",
    "\n",
    "        ###테스트\n",
    "\n",
    "        # yy_value=sess.run(predict , feed_dict={X:test,keep_rate:1})\n",
    "\n",
    "        # dfff=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "        # dfff[\"label\"]=yy_value\n",
    "        # arr=[]\n",
    "        # for dfffnum in range(0,len(dfff)):\n",
    "        #     arr=dfffnum\n",
    "\n",
    "        # print(dfffnum)\n",
    "\n",
    "\n",
    "\n",
    "        #=================\n",
    "\n",
    "\n",
    "        # n=0\n",
    "        # n1=100\n",
    "        # n2=100\n",
    "        # for i in range(140):\n",
    "        #     batch_x=train1_test[n:n2]\n",
    "        #     batch_y =df4_test[n:n2]\n",
    "        #     correct_num=sess.run(accuracy, feed_dict={X:batch_x , Y:batch_y ,keep_rate:1})\n",
    "        #     result_sum += correct_num\n",
    "        #     n=n+n1\n",
    "        #     n2=n2+n1\n",
    "\n",
    "\n",
    "        # #tf.cast(correct , dtype=tf.float32# 맞으면 1 틀리면 0 100개를 끌어왔는데 반은맞고 반은 틀리면 50이됨 \n",
    "        # #print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images,Y:mnist.test.labels,keep_rate:1})) )\n",
    "\n",
    "        # print(\"정확도:{}\".format(result_sum/14000))\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   번호\n",
      "0   0\n",
      "1   1\n",
      "2   2\n",
      "3   3\n",
      "4   4\n",
      "5   5\n",
      "6   6\n",
      "7   7\n",
      "8   8\n",
      "9   9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9\n",
       "0  1  0  0  0  0  0  0  0  0  0\n",
       "1  0  1  0  0  0  0  0  0  0  0\n",
       "2  0  0  1  0  0  0  0  0  0  0\n",
       "3  0  0  0  1  0  0  0  0  0  0\n",
       "4  0  0  0  0  1  0  0  0  0  0\n",
       "5  0  0  0  0  0  1  0  0  0  0\n",
       "6  0  0  0  0  0  0  1  0  0  0\n",
       "7  0  0  0  0  0  0  0  1  0  0\n",
       "8  0  0  0  0  0  0  0  0  1  0\n",
       "9  0  0  0  0  0  0  0  0  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 원핫 인코딩 방법들 \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "\n",
    "df1=pd.DataFrame()\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "df1=arr\n",
    "\n",
    "df2=pd.DataFrame()\n",
    "\n",
    "\n",
    "for n in range(0,10):\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "\n",
    "\n",
    "for n in range(0,tr2):\n",
    "    df2[n]=df1[train2[n]]\n",
    "\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "df4=df2.transpose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indices = [0, 1, 2,3,4,5,6,7,8,9]\n",
    "depth = 10\n",
    "one_hot2=tf.one_hot(indices, depth)  # output: [3 x 3]\n",
    "sess = tf.Session()\n",
    "print(sess.run(one_hot2))\n",
    "\n",
    "one_hot3=sess.run(one_hot2)\n",
    "\n",
    "display(one_hot3)\n",
    "\n",
    "df=pd.DataFrame({\"번호\":[0,1,2,3,4,5,6,7,8,9]})\n",
    "#music_dummy_mat = pd.get_dummies(music_df['music_genre'])\n",
    "\n",
    "print(df)\n",
    "df_dummy_mat = pd.get_dummies(df[\"번호\"])\n",
    "display(df_dummy_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클레스 = 틀\n",
    "\n",
    "# 틀에 맞춰서 일정공간 메모리 확보하는놈이 인스턴스 \n",
    "\n",
    "# 각 모델을 클레스의 인스턴스로 만들어서 관리\n",
    "\n",
    "# 우리가 만들 model의 데이터와 기능을 생각해서 클레스를\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "\n",
    "class CNNModel:\n",
    "    \n",
    "    \n",
    "    ###기능나열\n",
    "    #모델구축\n",
    "    #학습\n",
    "    #정확도\n",
    "    #예측값\n",
    "    \n",
    "    def __init__(self,sess,name,train1,train2)   #정해진 이름 클레스의 인스턴스를 만들때 가장먼저실행 생성자 \n",
    "                                    #초기값에 파라미터를 받게됨\n",
    "        self.sess=sess\n",
    "        self.name=name # 전달받을 name(지역변수)이 앞에 self.name(객체변수)은 객체내에서 사용하는 데이터 \n",
    "        self.train1=train1 #객체가 사용하는 데이터\n",
    "        self.train2=train2\n",
    "    def build(self):       #train1, train2\n",
    "        \n",
    "        df1=pd.DataFrame()\n",
    "        df2=pd.DataFrame()\n",
    "        df4=pd.DataFrame()\n",
    "\n",
    "        arr = np.zeros((10,10), dtype=np.int32)\n",
    "        df1=arr\n",
    "\n",
    "        for n in range(0,10):\n",
    "\n",
    "            df1[n,n]=1\n",
    "            df2[n]=np.arange(10)\n",
    "\n",
    "        tr2=int(len(self.train2))\n",
    "\n",
    "\n",
    "        for n in range(0,tr2):\n",
    "\n",
    "            df2[n]=df1[self.train2[n]]\n",
    "\n",
    "        df4=df2.transpose()  #y_data\n",
    "\n",
    "        number=int(len(train1)*2/3)\n",
    "\n",
    "\n",
    "        train1_1=self.train1[0:number]\n",
    "        train1_test=self.train1[number:-1]\n",
    "\n",
    "        df4_1=df4[0:number]\n",
    "        df4_test=df4[number:-1]\n",
    "\n",
    "\n",
    "        X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "        W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "        L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "        L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "        L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "        L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "        W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "        _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "        layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "        W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "        _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "        layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "        H = tf.matmul(layer2,W4)+b4\n",
    "        \n",
    "        cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "        train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "        sess=tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        return H\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def study(self)\n",
    "        self.sess.run([self.train.cost],feed_dict=[X:x_data,Y:y_data])\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "\n",
    "        print(int(nn))\n",
    "        for step in range(10):\n",
    "            num_of_iter = 42000\n",
    "\n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "\n",
    "\n",
    "                batch_x = self.train1[n:n2]\n",
    "                batch_y = df4[n:n2]\n",
    "                _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "        \n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "        \n",
    "        \n",
    "    def Predict(self,H):\n",
    "        predict = tf.argmax(H,1)\n",
    "        \n",
    "        return predict\n",
    "    def Correct(self,predict):   \n",
    "        correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "        return correct\n",
    "    def Accuracy(self,correct):\n",
    "        accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "        return accuracy\n",
    "    \n",
    "\n",
    "모델객체 생성    \n",
    "# model = CNNModel(\"model1\".sess)\n",
    "# model1.build()\n",
    "# model1.exec_train(x_data)\n",
    "\n",
    "\n",
    "models=[]\n",
    "num_models=10\n",
    "\n",
    "models.append(CNNModel(sess,model0))\n",
    "\n",
    "for m in range(num_models):\n",
    "    models.append(CNNModel(sess,\"model\"+str(m)))\n",
    "\n",
    "    \n",
    "\n",
    "models.build()\n",
    "models.exec_train(x_data)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "#학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Operation 'init' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"init\"\nop: \"NoOp\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 300\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    301\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3489\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3490\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3573\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3574\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Operation %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3575\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation name: \"init\"\nop: \"NoOp\"\n is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-76b40a791420>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;31m# sess = tf.Session()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-76b40a791420>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mkeep_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1137\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \"\"\"\n\u001b[0;32m    470\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    305\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 307\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    308\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Operation 'init' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"init\"\nop: \"NoOp\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False) #x_data\n",
    "train2=train[\"label\"]\n",
    "df1=pd.DataFrame()\n",
    "df2=pd.DataFrame()\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "df1=arr\n",
    "\n",
    "for n in range(0,10):\n",
    "\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "\n",
    "\n",
    "for n in range(0,tr2):\n",
    "\n",
    "    df2[n]=df1[train2[n]]\n",
    "\n",
    "df4=df2.transpose()  #y_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNNModel:\n",
    "    \n",
    "    \n",
    "    ###기능나열\n",
    "    #모델구축\n",
    "    #학습\n",
    "    #정확도\n",
    "    #예측값\n",
    "    \n",
    "    def __init__(self,sess,name,train1,df4):   #정해진 이름 클레스의 인스턴스를 만들때 가장먼저실행 생성자 \n",
    "                                    #초기값에 파라미터를 받게됨\n",
    "        self.sess=sess\n",
    "        self.name=name # 전달받을 name(지역변수)이 앞에 self.name(객체변수)은 객체내에서 사용하는 데이터 \n",
    "        self.train1=train1 #객체가 사용하는 데이터\n",
    "        self.df4=df4\n",
    "    def Build(self):       #train1, train2\n",
    "        \n",
    "        \n",
    "        X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "        Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "        X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "        W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "        L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "        L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "        L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "        L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "        W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "        _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "        layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "        W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "        _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "        layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "        W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "        \n",
    "        \n",
    "        self.H = tf.matmul(layer2,W4)+b4\n",
    "        \n",
    "        self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.H , labels=Y))\n",
    "\n",
    "        self.train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(self.cost)\n",
    "        \n",
    "        self.predict = tf.argmax(self.H,1)\n",
    "        self.correct=tf.equal(self.predict , tf.argmax(Y,1)) \n",
    "        self.accuracy=tf.reduce_sum(tf.cast(self.correct , dtype=tf.float32))\n",
    "        \n",
    "        \n",
    "    def Train(self):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        keep_rate=tf.placeholder(dtype=tf.float32)\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "\n",
    "        for step in range(10):\n",
    "            num_of_iter = 42000\n",
    "\n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "\n",
    "\n",
    "                batch_x = self.train1[n:n2]\n",
    "                batch_y = self.df4[n:n2]\n",
    "                _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.7})\n",
    "\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "        \n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "            \n",
    "        \n",
    "#    def predict(self):\n",
    "       \n",
    "        \n",
    "\n",
    "#모델객체 생성    \n",
    "# model = CNNModel(\"model1\".sess)\n",
    "# model1.build()\n",
    "# model1.exec_train(x_data)\n",
    "\n",
    "\n",
    "#models=[]\n",
    "#models.append\n",
    "\n",
    "\n",
    "# num_models=10\n",
    "\n",
    "\n",
    "\n",
    "# for m in range(num_models):\n",
    "#     models.append(CNNModel(sess,\"model\"+str(m),train1,df4))\n",
    "\n",
    "#print(CNNModel(sess,\"model0\",train1,df4).Train())    #H값 나오고\n",
    "#H2=CNNModel(sess,\"model0\",train1,df4).Train()\n",
    "\n",
    "print(H2)\n",
    "\n",
    "m1=CNNModel(sess,\"model0\",train1,df4)\n",
    "\n",
    "\n",
    "print(m1.Train())\n",
    "\n",
    "# sess = tf.Session()\n",
    "# H2=np.array\n",
    "# print(sess.run([H2],feed_dict={X:H1}))\n",
    "#models.exec_train(x_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Student:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,kor,eng,math):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.kor=kor\n",
    "        self.eng=eng\n",
    "        self.math=math\n",
    "    \n",
    "    def calc_avg(self):\n",
    "        return (self.kor+self.eng+self.math)/3\n",
    "stu1=Student(\"홍길동\",10,20,30)\n",
    "print(stu1.calc_avg())\n",
    "\n",
    "stu2=Student(\"김길동\",10,20,30)\n",
    "print(stu2.calc_avg())\n",
    "\n",
    "\n",
    "def __init__(self,sess,name,train1,df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0           0       0       0       0       0       0       0       0       0   \n",
      "1           0       0       0       0       0       0       0       0       0   \n",
      "2           0       0       0       0       0       0       0       0       0   \n",
      "3           0       0       0       0       0       0       0       0       0   \n",
      "4           0       0       0       0       0       0       0       0       0   \n",
      "5           0       0       0       0       0       0       0       0       0   \n",
      "6           0       0       0       0       0       0       0       0       0   \n",
      "7           0       0       0       0       0       0       0       0       0   \n",
      "8           0       0       0       0       0       0       0       0       0   \n",
      "9           0       0       0       0       0       0       0       0       0   \n",
      "10          0       0       0       0       0       0       0       0       0   \n",
      "11          0       0       0       0       0       0       0       0       0   \n",
      "12          0       0       0       0       0       0       0       0       0   \n",
      "13          0       0       0       0       0       0       0       0       0   \n",
      "14          0       0       0       0       0       0       0       0       0   \n",
      "15          0       0       0       0       0       0       0       0       0   \n",
      "16          0       0       0       0       0       0       0       0       0   \n",
      "17          0       0       0       0       0       0       0       0       0   \n",
      "18          0       0       0       0       0       0       0       0       0   \n",
      "19          0       0       0       0       0       0       0       0       0   \n",
      "20          0       0       0       0       0       0       0       0       0   \n",
      "21          0       0       0       0       0       0       0       0       0   \n",
      "22          0       0       0       0       0       0       0       0       0   \n",
      "23          0       0       0       0       0       0       0       0       0   \n",
      "24          0       0       0       0       0       0       0       0       0   \n",
      "25          0       0       0       0       0       0       0       0       0   \n",
      "26          0       0       0       0       0       0       0       0       0   \n",
      "27          0       0       0       0       0       0       0       0       0   \n",
      "28          0       0       0       0       0       0       0       0       0   \n",
      "29          0       0       0       0       0       0       0       0       0   \n",
      "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "41970       0       0       0       0       0       0       0       0       0   \n",
      "41971       0       0       0       0       0       0       0       0       0   \n",
      "41972       0       0       0       0       0       0       0       0       0   \n",
      "41973       0       0       0       0       0       0       0       0       0   \n",
      "41974       0       0       0       0       0       0       0       0       0   \n",
      "41975       0       0       0       0       0       0       0       0       0   \n",
      "41976       0       0       0       0       0       0       0       0       0   \n",
      "41977       0       0       0       0       0       0       0       0       0   \n",
      "41978       0       0       0       0       0       0       0       0       0   \n",
      "41979       0       0       0       0       0       0       0       0       0   \n",
      "41980       0       0       0       0       0       0       0       0       0   \n",
      "41981       0       0       0       0       0       0       0       0       0   \n",
      "41982       0       0       0       0       0       0       0       0       0   \n",
      "41983       0       0       0       0       0       0       0       0       0   \n",
      "41984       0       0       0       0       0       0       0       0       0   \n",
      "41985       0       0       0       0       0       0       0       0       0   \n",
      "41986       0       0       0       0       0       0       0       0       0   \n",
      "41987       0       0       0       0       0       0       0       0       0   \n",
      "41988       0       0       0       0       0       0       0       0       0   \n",
      "41989       0       0       0       0       0       0       0       0       0   \n",
      "41990       0       0       0       0       0       0       0       0       0   \n",
      "41991       0       0       0       0       0       0       0       0       0   \n",
      "41992       0       0       0       0       0       0       0       0       0   \n",
      "41993       0       0       0       0       0       0       0       0       0   \n",
      "41994       0       0       0       0       0       0       0       0       0   \n",
      "41995       0       0       0       0       0       0       0       0       0   \n",
      "41996       0       0       0       0       0       0       0       0       0   \n",
      "41997       0       0       0       0       0       0       0       0       0   \n",
      "41998       0       0       0       0       0       0       0       0       0   \n",
      "41999       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0           0  ...         0         0         0         0         0   \n",
      "1           0  ...         0         0         0         0         0   \n",
      "2           0  ...         0         0         0         0         0   \n",
      "3           0  ...         0         0         0         0         0   \n",
      "4           0  ...         0         0         0         0         0   \n",
      "5           0  ...         0         0         0         0         0   \n",
      "6           0  ...         0         0         0         0         0   \n",
      "7           0  ...         0         0         0         0         0   \n",
      "8           0  ...         0         0         0         0         0   \n",
      "9           0  ...         0         0         0         0         0   \n",
      "10          0  ...         0         0         0         0         0   \n",
      "11          0  ...         0         0         0         0         0   \n",
      "12          0  ...         0         0         0         0         0   \n",
      "13          0  ...         0         0         0         0         0   \n",
      "14          0  ...         0         0         0         0         0   \n",
      "15          0  ...         0         0         0         0         0   \n",
      "16          0  ...         0         0         0         0         0   \n",
      "17          0  ...         0         0         0         0         0   \n",
      "18          0  ...         0         0         0         0         0   \n",
      "19          0  ...         0         0         0         0         0   \n",
      "20          0  ...         0         0         0         0         0   \n",
      "21          0  ...         0         0         0         0         0   \n",
      "22          0  ...         0         0         0         0         0   \n",
      "23          0  ...         0         0         0         0         0   \n",
      "24          0  ...         0         0         0         0         0   \n",
      "25          0  ...         0         0         0         0         0   \n",
      "26          0  ...         0         0         0         0         0   \n",
      "27          0  ...         0         0         0         0         0   \n",
      "28          0  ...         0         0         0         0         0   \n",
      "29          0  ...         0         0         0         0         0   \n",
      "...       ...  ...       ...       ...       ...       ...       ...   \n",
      "41970       0  ...         0         0         0         0         0   \n",
      "41971       0  ...         0         0         0         0         0   \n",
      "41972       0  ...         0         0         0         0         0   \n",
      "41973       0  ...         0         0         0         0         0   \n",
      "41974       0  ...         0         0         0         0         0   \n",
      "41975       0  ...         0         0         0         0         0   \n",
      "41976       0  ...         0         0         0         0         0   \n",
      "41977       0  ...         0         0         0         0         0   \n",
      "41978       0  ...         0         0         0         0         0   \n",
      "41979       0  ...         0         0         0         0         0   \n",
      "41980       0  ...        27       253       110         0         0   \n",
      "41981       0  ...         0         0         0         0         0   \n",
      "41982       0  ...         0         0         0         0         0   \n",
      "41983       0  ...         0         0         0         0         0   \n",
      "41984       0  ...         0         0         0         0         0   \n",
      "41985       0  ...         0         0         0         0         0   \n",
      "41986       0  ...         0         0         0         0         0   \n",
      "41987       0  ...         0         0         0         0         0   \n",
      "41988       0  ...         0         0         0         0         0   \n",
      "41989       0  ...         0         0         0         0         0   \n",
      "41990       0  ...         0         0         0         0         0   \n",
      "41991       0  ...         0         0         0         0         0   \n",
      "41992       0  ...         0         0         0         0         0   \n",
      "41993       0  ...         0         0         0         0         0   \n",
      "41994       0  ...         0         0         0         0         0   \n",
      "41995       0  ...         0         0         0         0         0   \n",
      "41996       0  ...         0         0         0         0         0   \n",
      "41997       0  ...         0         0         0         0         0   \n",
      "41998       0  ...         0         0         0         0         0   \n",
      "41999       0  ...         0         0         0         0         0   \n",
      "\n",
      "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0             0         0         0         0         0  \n",
      "1             0         0         0         0         0  \n",
      "2             0         0         0         0         0  \n",
      "3             0         0         0         0         0  \n",
      "4             0         0         0         0         0  \n",
      "5             0         0         0         0         0  \n",
      "6             0         0         0         0         0  \n",
      "7             0         0         0         0         0  \n",
      "8             0         0         0         0         0  \n",
      "9             0         0         0         0         0  \n",
      "10            0         0         0         0         0  \n",
      "11            0         0         0         0         0  \n",
      "12            0         0         0         0         0  \n",
      "13            0         0         0         0         0  \n",
      "14            0         0         0         0         0  \n",
      "15            0         0         0         0         0  \n",
      "16            0         0         0         0         0  \n",
      "17            0         0         0         0         0  \n",
      "18            0         0         0         0         0  \n",
      "19            0         0         0         0         0  \n",
      "20            0         0         0         0         0  \n",
      "21            0         0         0         0         0  \n",
      "22            0         0         0         0         0  \n",
      "23            0         0         0         0         0  \n",
      "24            0         0         0         0         0  \n",
      "25            0         0         0         0         0  \n",
      "26            0         0         0         0         0  \n",
      "27            0         0         0         0         0  \n",
      "28            0         0         0         0         0  \n",
      "29            0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "41970         0         0         0         0         0  \n",
      "41971         0         0         0         0         0  \n",
      "41972         0         0         0         0         0  \n",
      "41973         0         0         0         0         0  \n",
      "41974         0         0         0         0         0  \n",
      "41975         0         0         0         0         0  \n",
      "41976         0         0         0         0         0  \n",
      "41977         0         0         0         0         0  \n",
      "41978         0         0         0         0         0  \n",
      "41979         0         0         0         0         0  \n",
      "41980         0         0         0         0         0  \n",
      "41981         0         0         0         0         0  \n",
      "41982         0         0         0         0         0  \n",
      "41983         0         0         0         0         0  \n",
      "41984         0         0         0         0         0  \n",
      "41985         0         0         0         0         0  \n",
      "41986         0         0         0         0         0  \n",
      "41987         0         0         0         0         0  \n",
      "41988         0         0         0         0         0  \n",
      "41989         0         0         0         0         0  \n",
      "41990         0         0         0         0         0  \n",
      "41991         0         0         0         0         0  \n",
      "41992         0         0         0         0         0  \n",
      "41993         0         0         0         0         0  \n",
      "41994         0         0         0         0         0  \n",
      "41995         0         0         0         0         0  \n",
      "41996         0         0         0         0         0  \n",
      "41997         0         0         0         0         0  \n",
      "41998         0         0         0         0         0  \n",
      "41999         0         0         0         0         0  \n",
      "\n",
      "[42000 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False) #x_data\n",
    "train2=train[\"label\"]\n",
    "df1=pd.DataFrame()\n",
    "df2=pd.DataFrame()\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "df1=arr\n",
    "\n",
    "for n in range(0,10):\n",
    "\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "\n",
    "\n",
    "for n in range(0,tr2):\n",
    "\n",
    "    df2[n]=df1[train2[n]]\n",
    "\n",
    "df4=df2.transpose()  #y_data\n",
    "keep_rate=tf.placeholder(dtype=tf.float32)\n",
    "keep_rate=0.5\n",
    "\n",
    "print(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Student:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,kor,eng,math):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.kor=kor\n",
    "        self.eng=eng\n",
    "        self.math=math\n",
    "    \n",
    "    def calc_avg(self):\n",
    "        return (self.kor+self.eng+self.math)/3\n",
    "stu1=Student(\"홍길동\",10,20,30)\n",
    "print(stu1.calc_avg())\n",
    "\n",
    "stu2=Student(\"김길동\",10,20,30)\n",
    "print(stu2.calc_avg())\n",
    "\n",
    "\n",
    "def __init__(self,sess,name,train1,df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "train1=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    "X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "keep_rate=tf.placeholder(dtype=tf.float32)  #드랍아웃에서 얼마나 살릴지\n",
    "\n",
    "\n",
    "df1=pd.DataFrame()\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "\n",
    "df1=arr\n",
    "\n",
    "df2=pd.DataFrame()\n",
    "\n",
    "\n",
    "for n in range(0,10):\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "\n",
    "\n",
    "for n in range(0,tr2):\n",
    "    df2[n]=df1[train2[n]]\n",
    "\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "df4=df2.transpose()\n",
    "\n",
    "\n",
    "number=int(len(train1)*2/3)\n",
    "\n",
    "train1_1=train1[0:number]\n",
    "train1_test=train1[number:-1]\n",
    "\n",
    "df4_1=df4[0:number]\n",
    "df4_test=df4[number:-1]\n",
    "\n",
    "\n",
    "X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "L1 = tf.nn.relu(L1)\n",
    "p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "layer1 = tf.nn.dropout(_layer1 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "layer2 = tf.nn.dropout(_layer2 , keep_prob=keep_rate)\n",
    "\n",
    "\n",
    "W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "\n",
    "# hypothesis 가설만들어야함\n",
    "\n",
    "\n",
    "H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "#cost 함수\n",
    "\n",
    "cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H , labels=Y))\n",
    "\n",
    "\n",
    "\n",
    "number=0\n",
    "float(number)\n",
    "\n",
    "\n",
    "\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "\n",
    "num_of_epoch = 10\n",
    "batch_size=100\n",
    "\n",
    "\n",
    "\n",
    "n=0\n",
    "n1=100\n",
    "n2=100\n",
    "\n",
    "\n",
    "for step in range(10):\n",
    "    num_of_iter = 42000\n",
    "    print(step)\n",
    "    n=0\n",
    "    n1=100\n",
    "    n2=100\n",
    "\n",
    "    for i in range(420):\n",
    "\n",
    "\n",
    "        batch_x = train1[n:n2]\n",
    "        batch_y = df4[n:n2]\n",
    "        _,cost_val=sess.run([train,cost], feed_dict={X:batch_x , Y:batch_y ,keep_rate:0.5\n",
    "                                                    })\n",
    "\n",
    "        n=n+n1\n",
    "        n2=n2+n1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "accuracy=tf.reduce_sum(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "result_sum=0\n",
    "num_of_iter = int(num_of_iter/100)\n",
    "\n",
    "\n",
    "\n",
    "### 라벨 뽑기 predict 이용\n",
    "\n",
    "\n",
    "yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "\n",
    "# n=0\n",
    "# n1=100\n",
    "# n2=100\n",
    "\n",
    "# for i in range(280):\n",
    "#     batch_x=test[n:n2]\n",
    "\n",
    "#     yy_value[\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "\n",
    "#     n=n+n1\n",
    "#     n2=n2+n1\n",
    "\n",
    "# print(yy_value)\n",
    "# print(\"=========\")\n",
    "\n",
    "\n",
    "n=0\n",
    "n1=100\n",
    "n2=100\n",
    "a=[]\n",
    "\n",
    "for i in range(280):\n",
    "    batch_x=test[n:n2]\n",
    "\n",
    "    #yy_value.loc[n:n2,\"Label\"]=sess.run(predict, feed_dict={X:batch_x,keep_rate:1})\n",
    "    a.extend(sess.run(predict, feed_dict={X:batch_x,keep_rate:1}))\n",
    "    \n",
    "    n=n+n1\n",
    "    n2=n2+n1\n",
    "\n",
    "print(\"=========\")\n",
    "\n",
    "yy_value=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "\n",
    "yy_value[\"Label\"]=a\n",
    "\n",
    "nnn=[]\n",
    "for nnnn in range(1,28001):\n",
    "    nnn.append(nnnn)\n",
    "\n",
    "yy_value[\"ImageId\"]=nnn\n",
    "print(yy_value)\n",
    "\n",
    "\n",
    "yy_value.to_csv(\"./data/submit_mnistwow\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# yy_value=sess.run(predict , feed_dict={X:test,keep_rate:1})\n",
    "\n",
    "# dfff=pd.DataFrame(columns=[\"ImageId\",\"Label\"])\n",
    "# dfff[\"label\"]=yy_value\n",
    "# arr=[]\n",
    "# for dfffnum in range(0,len(dfff)):\n",
    "#     arr=dfffnum\n",
    "\n",
    "# print(dfffnum)\n",
    "\n",
    "\n",
    "\n",
    "###테스트\n",
    "\n",
    "\n",
    "\n",
    "n=0\n",
    "n1=100\n",
    "n2=100\n",
    "for i in range(140):\n",
    "    batch_x=train1_test[n:n2]\n",
    "    batch_y =df4_test[n:n2]\n",
    "    correct_num=sess.run(accuracy, feed_dict={X:batch_x , Y:batch_y ,keep_rate:1})\n",
    "    result_sum += correct_num\n",
    "    n=n+n1\n",
    "    n2=n2+n1\n",
    "\n",
    "\n",
    "#tf.cast(correct , dtype=tf.float32# 맞으면 1 틀리면 0 100개를 끌어왔는데 반은맞고 반은 틀리면 50이됨 \n",
    "#print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images,Y:mnist.test.labels,keep_rate:1})) )\n",
    "\n",
    "print(\"{}번째: , 정확도:{}\".format(number,result_sum/14000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
