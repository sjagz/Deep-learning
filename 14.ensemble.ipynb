{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-6bbd64e7d05f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mtr2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3445\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3660\u001b[0m         \u001b[1;31m# broadcast across multiple columns if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3661\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mbroadcast\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3662\u001b[0m             if (not self.columns.is_unique or\n\u001b[0;32m   3663\u001b[0m                     isinstance(self.columns, MultiIndex)):\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\pandas\\core\\indexes\\numeric.py\u001b[0m in \u001b[0;36m__contains__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOverflowError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "\n",
    "### x_data , y_data , dataframe 형태\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "x_data=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    " \n",
    "df1=pd.DataFrame()\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "df1=arr\n",
    "df2=pd.DataFrame()\n",
    "for n in range(0,10):\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "for n in range(0,tr2):\n",
    "    df2[n]=df1[train2[n]]\n",
    "y_data=pd.DataFrame()\n",
    "y_data=df2.transpose()\n",
    "\n",
    "\n",
    "x_data=x_data.values\n",
    "y_data=y_data.values\n",
    "### x_data , y_data , dataframe 형태 넘파이 어레이가 공통적으로 쓰임\n",
    "\n",
    "class CNNModel: \n",
    "    \n",
    "    def __init__(self,sess,name):     \n",
    "\n",
    "        self.sess=sess\n",
    "        self.name=name \n",
    "        \n",
    "    def build_graph(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "            self.Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "            self.keep_rate=tf.placeholder(dtype=tf.float32) \n",
    "            \n",
    "            X_img = tf.reshape(self.X, shape=[-1,28,28,1])\n",
    "\n",
    "            W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "            L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "            L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "            L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "            L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "            W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "            _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "            layer1 = tf.nn.dropout(_layer1 , keep_prob=self.keep_rate)\n",
    "\n",
    "\n",
    "            W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "            _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "            layer2 = tf.nn.dropout(_layer2 , keep_prob=self.keep_rate)\n",
    "\n",
    "\n",
    "            W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "\n",
    "            self.H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "            self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.H , labels=self.Y))\n",
    "\n",
    "            self.train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(self.cost)\n",
    "\n",
    "            self.predict = tf.argmax(self.H,1)\n",
    "            self.correct=tf.equal(self.predict , tf.argmax(self.Y,1)) \n",
    "\n",
    "            self.accuracy=tf.reduce_sum(tf.cast(self.correct , dtype=tf.float32))\n",
    "\n",
    "    \n",
    "    def train_model(self,x,y):\n",
    "\n",
    "        \n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        for step in range(10):\n",
    "            \n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "                batch_x = x[n:n2]\n",
    "                batch_y = y[n:n2]\n",
    "                _,cost_val=self.sess.run([self.train,self.cost], feed_dict={self.X:batch_x,self.Y:batch_y \n",
    "                                                                            ,self.keep_rate:0.5})\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "    def H_value(self,x):\n",
    "        \n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        H_val_arraysum=[]\n",
    "        H_val_arraysumDF=pd.DataFrame()\n",
    "        #H_val_arraysumDF=pd.DataFrame\n",
    "        ran=420\n",
    "        for i in range(ran):\n",
    "            batch_x = x[n:n2]\n",
    "            H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:0.5 }))\n",
    "            H_val_arraysum.extend(H_val) # 리스트방법\n",
    "            \n",
    "            \n",
    "            #H_val_arraysumDF=pd.DataFrame(H_val)\n",
    "            #if i>=2:\n",
    "            #    H_val_arraysumDFresult=pd.merge((H_val_arraysumDF(i)),(H_val_arraysumDF(i+1)),how=\"outer\")\n",
    "            #c=np.vstack((H_val,H_val))\n",
    "            \n",
    "            #H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:1 }))\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "        #print(\"H : {}\".format(H_val))\n",
    "        \n",
    "        #return self.sess.run(self.H, feed_dict={self.X:x , self.keep_rate:1 })\n",
    "        return H_val_arraysum\n",
    "    \n",
    "    \n",
    "    def H_value_sum(self,x,y):\n",
    "        \n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        H_val_arraysum=[]\n",
    "        H_zero = np.zeros((100,10),dtype=np.float32)\n",
    "        ran=420\n",
    "        for i in range(ran):\n",
    "            ### 모델 10개\n",
    "            model_list = [\"m0\",\"m1\"]#,\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "            \n",
    "            for k in model_list:\n",
    "                batch_x = x[n:n2]\n",
    "                batch_y = y[n:n2]\n",
    "                H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:0.5 }))\n",
    "\n",
    "                H_zero=H_zero+H_val\n",
    "            \n",
    "            H_modelsum=H_zero/10\n",
    "            \n",
    "            _,cost_val=self.sess.run([self.train,self.cost], feed_dict={self.H:H_modelsum , self.Y:batch_y , self.keep_rate:0.5})\n",
    "            ### 모델 10개 끝\n",
    "            \n",
    "            ##시험삼아\n",
    "#             self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.H , labels=self.Y))\n",
    "\n",
    "#             self.train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(self.cost)\n",
    "\n",
    "#             self.predict = tf.argmax(self.H,1)\n",
    "#             self.correct=tf.equal(self.predict , tf.argmax(self.Y,1)) \n",
    "\n",
    "#             self.accuracy=tf.reduce_sum(tf.cast(self.correct , dtype=tf.float32))\n",
    "            \n",
    "            ######    시험삼아\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "      \n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "        ##모델 10개\n",
    "#         def model(self)\n",
    "#         model_list = [\"m0\",\"m1\"]#,\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "            \n",
    "#             for k in model_list:\n",
    "#                 batch_x = x[n:n2]\n",
    "#                 batch_y = y[n:n2]\n",
    "#                 H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:0.5 }))\n",
    "\n",
    "#                 H_zero=H_zero+H_val\n",
    "            \n",
    "#             H_modelsum=H_zero/10\n",
    "#         ###모델 10개    \n",
    "           # _,cost_val=self.sess.run([self.train,self.cost], feed_dict={self.H:H_modelsum , self.Y:batch_y , self.keep_rate:0.5})\n",
    "            \n",
    "#     def predict(self):\n",
    "#     def correct(self):\n",
    "#     def accuracy(self):\n",
    "\n",
    "sess=tf.Session()\n",
    "\n",
    "#for model_roof in range(5):\n",
    "\n",
    "# model_list = [\"m0\",\"m1\",\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "# model_roof=0\n",
    "# for k in model_list:\n",
    "    \n",
    "k=CNNModel(sess,\"model1\")   #객체생성\n",
    "k1=k.build_graph()             #모델생성   m1이 빌드 그래프를 가지고 있다 \n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#m1.train_model(x_data,y_data)\n",
    "\n",
    "#print(m1.H_value(x_data)) # [[-3.2657056   0.75052345 -1.8666681    2.8347716   1.7404464   3.1127691 ][][]...[]]100개\n",
    "\n",
    "\n",
    "\n",
    "k1.H_value_sum(x_data,y_data)\n",
    "\n",
    "\n",
    "\n",
    "# 42000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.15280664e-01 -2.59530604e-01 -2.43090510e-01  4.81846720e-01\n",
      "  -9.74919200e-02  4.64347303e-01 -8.63171399e-01 -9.79597569e-02\n",
      "  -3.60020131e-01  1.37562490e+00]\n",
      " [-3.20999837e+00 -2.73733616e+00  4.44712698e-01  1.12117648e+00\n",
      "   2.12275457e+00  3.06936502e+00 -1.28460288e+00  3.53754133e-01\n",
      "   9.98587757e-02  1.10312030e-01]\n",
      " [-2.51605898e-01 -2.96605714e-02 -6.95361674e-01  6.49563551e-01\n",
      "   3.97425950e-01 -7.55857110e-01  4.07875717e-01 -2.37087637e-01\n",
      "   5.99240303e-01  1.11820865e+00]\n",
      " [-1.75812149e+00 -1.12838817e+00 -5.22349954e-01 -8.17737401e-01\n",
      "   5.60075104e-01 -5.38276315e-01 -8.07640731e-01 -8.68142009e-01\n",
      "  -1.51702428e+00  1.45308092e-01]\n",
      " [-1.73375928e+00  2.68738806e-01  1.12922117e-01  1.04283404e+00\n",
      "   1.02029383e+00  5.91213882e-01 -1.06042540e+00  8.92904878e-01\n",
      "   6.34238273e-02 -1.10842013e+00]\n",
      " [-1.26369989e+00 -1.20135200e+00  1.80810779e-01 -7.69256294e-01\n",
      "   1.20329630e+00  1.17417932e+00 -1.89351213e+00 -5.90192020e-01\n",
      "  -3.47127616e-01  1.60227966e+00]\n",
      " [-3.94591093e-01 -3.12433183e-01 -1.70729920e-01  5.33997416e-01\n",
      "  -2.99117081e-02 -1.94474220e-01 -6.41567886e-01 -1.34979412e-01\n",
      "   1.74752232e-02  5.39370239e-01]\n",
      " [-2.61244923e-01 -9.43911195e-01 -1.76736069e+00 -3.35431278e-01\n",
      "   2.38955164e+00 -2.20578223e-01 -3.04742312e+00  6.81336284e-01\n",
      "  -4.68348175e-01 -1.97389368e-02]\n",
      " [-2.06553078e+00  5.71492732e-01 -1.84081584e-01  2.39838958e-01\n",
      "   7.62001157e-01  1.38995147e+00 -3.94623339e-01 -5.72595775e-01\n",
      "   6.40514672e-01  3.33223552e-01]\n",
      " [-9.62804973e-01 -1.26792550e+00 -1.99835211e-01 -5.36267459e-01\n",
      "   9.74962056e-01  9.56729531e-01 -1.39640212e+00  1.09328294e+00\n",
      "  -1.08423686e+00  1.03027987e+00]\n",
      " [-6.98388100e-01 -4.40122187e-01 -9.59603131e-01 -7.25813687e-01\n",
      "   4.30415452e-01  1.14156270e+00 -7.75189340e-01  1.49835849e+00\n",
      "  -4.18340862e-01  1.30628204e+00]\n",
      " [-3.88260275e-01 -1.70857275e+00 -6.44097984e-01  4.32630539e-01\n",
      "   1.06914139e+00  9.43859577e-01  6.57506824e-01  1.51851460e-01\n",
      "  -6.71227455e-01  2.47722745e-01]\n",
      " [-2.35141009e-01 -5.96066654e-01  4.23491865e-01  5.82766756e-02\n",
      "  -3.85199219e-01 -2.48817690e-02 -1.38189465e-01  7.31377959e-01\n",
      "  -1.96900547e-01  8.71002197e-01]\n",
      " [-1.38931727e+00 -1.45088804e+00  1.49449155e-01  4.97880399e-01\n",
      "   2.38989019e+00  9.23847079e-01 -4.17199701e-01 -1.60702419e+00\n",
      "   6.61826730e-01  1.32294393e+00]\n",
      " [-3.64963675e+00 -2.70770669e-01  1.57222745e-03 -2.41604590e+00\n",
      "   5.63992321e-01  2.27891013e-01 -3.41063321e-01  6.98786080e-01\n",
      "  -6.77194238e-01  2.11527586e+00]\n",
      " [ 3.37530732e-01  1.28894746e-02 -3.32919538e-01 -1.11621559e+00\n",
      "   8.08605194e-01  3.71239195e-03 -4.86454725e-01 -1.93713993e-01\n",
      "  -7.85189033e-01  4.60347325e-01]\n",
      " [-1.11482167e+00 -1.04891181e+00  2.63118482e+00  1.92494273e-01\n",
      "   1.56056952e+00  1.29820991e+00 -1.68167996e+00  2.08537793e+00\n",
      "  -2.22512722e+00  2.09320545e+00]\n",
      " [-2.09003711e+00 -1.98651850e+00  1.76674497e+00 -1.14584148e+00\n",
      "   7.17052445e-02  5.74555516e-01 -1.08546662e+00 -1.49048388e+00\n",
      "   9.80496049e-01  1.98891258e+00]\n",
      " [-5.23178339e-01 -4.72027600e-01  5.43932676e-01 -5.32066047e-01\n",
      "   7.90467918e-01  8.22799504e-01 -9.20869052e-01  6.32345200e-01\n",
      "   1.48760140e-01  1.02960564e-01]\n",
      " [-2.75850415e+00 -2.10078740e+00 -1.43370855e+00 -2.28393173e+00\n",
      "   2.12636232e+00  3.02998096e-01 -1.59702313e+00 -1.54139951e-01\n",
      "  -9.85333562e-01  2.53345418e+00]\n",
      " [-2.34778690e+00 -1.58556044e+00 -1.36308098e+00 -6.06738210e-01\n",
      "   2.44208090e-02  1.35109675e+00 -2.06712437e+00  7.31560588e-01\n",
      "  -1.34745812e+00  1.05083132e+00]\n",
      " [ 7.25594386e-02 -1.18230440e-01  2.51600772e-01  3.93838882e-01\n",
      "   1.21981835e+00  2.44109106e+00 -2.77411032e+00  7.96270370e-03\n",
      "  -7.91187644e-01  2.57131958e+00]\n",
      " [-1.07123899e+00 -7.79245555e-01 -5.74477732e-01 -1.64224148e+00\n",
      "   3.68400335e-01  2.07384467e-01 -1.92246795e+00 -5.89803696e-01\n",
      "   1.75988436e-01  9.80318367e-01]\n",
      " [-3.12033987e+00 -4.61443901e-01  2.05122161e+00  1.69853425e+00\n",
      "  -8.74520957e-01  4.72319603e-01 -7.79482961e-01  1.58353734e+00\n",
      "  -1.34407234e+00  1.43190491e+00]\n",
      " [-1.14956164e+00  2.41490990e-01 -7.96493173e-01  1.09659445e+00\n",
      "   3.65272999e-01 -2.07528949e-01  3.24937493e-01  9.86659825e-01\n",
      "   1.49175122e-01  1.23272133e+00]\n",
      " [-2.10279512e+00 -2.22553015e+00 -3.54479790e-01 -7.69429088e-01\n",
      "  -6.20419204e-01  1.08771348e+00 -2.48425055e+00 -1.05802871e-01\n",
      "  -1.35177481e+00  3.66469049e+00]\n",
      " [-1.66006017e+00 -2.63315892e+00  1.07498169e-01  4.33313847e-01\n",
      "  -3.38244587e-01  3.71129811e-01 -6.95374787e-01  2.50564194e+00\n",
      "   2.99876750e-01  1.26829040e+00]\n",
      " [-1.10531175e+00 -1.37767577e+00 -6.90847754e-01  8.40338111e-01\n",
      "   8.92519772e-01  8.62184227e-01 -9.23572361e-01  8.84720445e-01\n",
      "  -1.14876425e+00  1.42429292e+00]\n",
      " [-8.59162360e-02 -2.19393015e+00 -1.34875071e+00  1.31776899e-01\n",
      "   2.94867563e+00  5.44297338e-01 -1.00285053e+00  1.32139623e+00\n",
      "  -9.44893956e-01  1.23431611e+00]\n",
      " [-1.25794291e+00 -7.89790511e-01 -7.66025186e-01  1.22446917e-01\n",
      "   1.68214515e-01  2.14012504e+00  4.28946018e-01  3.43804657e-01\n",
      "  -9.22982693e-02  1.62369037e+00]\n",
      " [-1.47538304e+00 -9.54079986e-01  2.31687516e-01 -1.86263978e+00\n",
      "   3.99105144e+00  1.18293858e+00 -1.26031041e+00  5.25669277e-01\n",
      "   7.66479850e-01  1.38424516e+00]\n",
      " [-4.74802434e-01  8.46053720e-01 -8.23592782e-01 -3.13128173e-01\n",
      "   1.76767981e+00 -6.57338127e-02 -1.86115384e+00  2.60666162e-01\n",
      "   1.32703170e-01  2.66423082e+00]\n",
      " [-1.92951870e+00 -8.02324653e-01  4.96576309e-01  1.13421881e+00\n",
      "   9.56672072e-01  1.11999440e+00 -1.05925429e+00 -8.44669700e-01\n",
      "  -3.70756567e-01 -1.35197735e+00]\n",
      " [ 9.77856338e-01  4.25809771e-01 -9.06525135e-01 -9.08295512e-01\n",
      "   2.17992449e+00  2.96741486e-01 -2.56999254e+00 -8.75561118e-01\n",
      "   8.87910247e-01 -3.13098013e-01]\n",
      " [-3.14651400e-01 -2.54619122e-01  8.88645530e-01  3.72057930e-02\n",
      "   1.17730224e+00 -7.17153728e-01 -8.20269942e-01  6.57955050e-01\n",
      "   1.64043427e+00  2.46659493e+00]\n",
      " [-4.23640668e-01 -1.73427284e-01 -1.04914248e+00  3.59898150e-01\n",
      "   2.62583584e-01  4.37536806e-01  5.42762280e-01 -4.44595516e-01\n",
      "   1.16888642e+00 -2.33218044e-01]\n",
      " [-1.47489369e+00 -2.38550496e+00 -3.52619648e-01 -8.09892833e-01\n",
      "   1.08696151e+00  1.11802864e+00 -3.41731422e-02 -3.66298497e-01\n",
      "  -5.82151532e-01  2.05837440e+00]\n",
      " [ 3.09763074e-01 -1.17962050e+00 -3.43064606e-01 -7.47542858e-01\n",
      "   4.37998682e-01  1.29605031e+00 -1.35522580e+00  2.43041277e-01\n",
      "  -7.33440757e-01  6.99067712e-01]\n",
      " [ 8.42958540e-02 -1.33882195e-01 -1.69108942e-01  9.04870391e-01\n",
      "   1.10430337e-01  1.21772075e+00 -7.08151877e-01  4.66263384e-01\n",
      "   5.50338864e-01  1.37968922e+00]\n",
      " [-6.36342615e-02 -7.28544831e-01 -3.77835512e-01 -1.01162314e+00\n",
      "   1.77062917e+00  3.76801252e-01 -7.82302678e-01  7.86830664e-01\n",
      "  -4.98762906e-01  9.67512429e-01]\n",
      " [-1.93365169e+00 -9.00149941e-01  1.29478157e+00  3.85507345e-01\n",
      "   7.18635440e-01  1.09141803e+00 -5.29230475e-01 -1.16692506e-01\n",
      "   7.98958123e-01  8.78421009e-01]\n",
      " [-8.42343330e-01 -8.18421364e-01  1.08012450e+00  7.35490322e-01\n",
      "  -4.97408807e-01  1.35687447e+00  6.86248183e-01  8.61616910e-01\n",
      "   2.05317825e-01  2.43647784e-01]\n",
      " [-2.87210846e+00 -4.13234711e-01  4.04280335e-01  1.81056574e-01\n",
      "   1.31396639e+00  1.62079751e+00 -3.36487830e-01 -1.49001434e-01\n",
      "  -6.46259546e-01  5.16871095e-01]\n",
      " [ 1.16478965e-01 -1.80082107e+00  7.24007010e-01 -2.16130346e-01\n",
      "   1.37797832e+00  1.10008693e+00 -1.48200822e+00  1.38632607e+00\n",
      "  -3.63166809e+00  3.82920802e-01]\n",
      " [-1.73395991e+00 -1.86017704e+00 -6.54601216e-01 -4.86639030e-02\n",
      "   3.15637171e-01  2.15909332e-01 -2.89025354e+00  1.07911801e+00\n",
      "  -2.91480601e-01  2.28377390e+00]\n",
      " [-4.51737070e+00  4.32160467e-01 -4.10560191e-01  1.39458656e-01\n",
      "  -2.03618097e+00  9.22967941e-02 -4.29673016e-01  7.16647625e-01\n",
      "  -6.60434902e-01  9.18560386e-01]\n",
      " [-1.00660396e+00 -2.95832992e-01  3.09176743e-01  3.32513660e-01\n",
      "  -7.18584880e-02 -2.41465084e-02  4.88047600e-01  2.58109361e-01\n",
      "   1.07681489e+00  1.05033088e+00]\n",
      " [-1.26167810e+00 -1.53134894e+00 -5.79420209e-01 -7.80599236e-01\n",
      "   9.86742616e-01  2.71008015e-02 -8.53724360e-01  6.91928983e-01\n",
      "  -3.28836054e-01  6.81491554e-01]\n",
      " [-1.36743665e+00 -4.42077726e-01 -2.20857739e-01 -9.92495656e-01\n",
      "   4.41233814e-01  2.98676401e-01 -8.07079494e-01 -5.30708790e-01\n",
      "  -8.75724331e-02  1.14048791e+00]\n",
      " [-2.75969601e+00 -1.02759004e+00 -2.50135183e-01 -1.17130876e+00\n",
      "   1.14011633e+00 -3.23630333e-01 -3.88539806e-02  3.48623812e-01\n",
      "  -4.12992060e-01  3.04258490e+00]\n",
      " [-8.87966156e-01 -4.03622925e-01  2.72357941e-01 -3.46911997e-01\n",
      "   9.97080028e-01  3.56507152e-01 -1.24366689e+00 -2.13100672e-01\n",
      "  -9.35002446e-01  1.47048146e-01]\n",
      " [-3.48499179e+00 -7.74748683e-01  3.02801704e+00  4.24044311e-01\n",
      "   1.57107985e+00  2.39320707e+00 -1.92901361e+00  1.89535424e-01\n",
      "   1.01454759e+00  1.12176740e+00]\n",
      " [-3.58064353e-01 -1.46017289e+00 -4.64377813e-02  3.89563143e-01\n",
      "   2.28402466e-01 -1.09752417e-02 -8.84499729e-01 -6.32234931e-01\n",
      "   1.90401614e-01  5.79116285e-01]\n",
      " [-1.30194497e+00 -1.33735728e+00  7.57547319e-01  1.80079892e-01\n",
      "  -1.37032354e+00  2.39231944e+00  3.39510113e-01 -1.17533967e-01\n",
      "  -1.47437894e+00  5.17093599e-01]\n",
      " [-2.18580627e+00 -7.27540374e-01 -1.24760818e+00  7.89990544e-01\n",
      "  -8.88787627e-01  4.98343378e-01 -9.95139420e-01 -3.00884247e-04\n",
      "  -3.23937386e-01  1.27600253e+00]\n",
      " [-1.53982735e+00 -7.59082019e-01  7.00989127e-01 -1.00639665e+00\n",
      "  -1.38084412e-01  3.59512508e-01 -2.98986018e-01  2.59127229e-01\n",
      "  -2.78523862e-01  1.65986502e+00]\n",
      " [-2.03036642e+00 -8.52747321e-01 -1.39371917e-01  7.81095862e-01\n",
      "  -3.30905944e-01 -3.42784554e-01 -2.16897681e-01  3.77670109e-01\n",
      "  -3.85017544e-01  1.37462676e+00]\n",
      " [-2.00294852e+00 -1.13432741e+00  1.37717056e+00  5.06186903e-01\n",
      "   2.71855742e-01  1.67089427e+00 -2.36104679e+00  3.90539259e-01\n",
      "  -5.22427320e-01  1.96177232e+00]\n",
      " [-1.20205474e+00 -1.82017231e+00  8.67329895e-01  6.86848581e-01\n",
      "   1.26400876e+00 -9.64056700e-02 -8.91433597e-01  2.23680437e-02\n",
      "  -4.52543795e-01  1.70586228e+00]\n",
      " [-8.79798412e-01 -5.89317679e-01 -7.70780683e-01  1.80296630e-01\n",
      "   5.98479390e-01  5.19729495e-01 -3.68546426e-01 -8.75879303e-02\n",
      "  -2.46696956e-02  6.59848869e-01]\n",
      " [-7.88636506e-01 -1.69736075e+00 -1.92873001e+00  1.31074905e+00\n",
      "   6.95018768e-01 -8.58565509e-01 -2.86165059e-01 -3.22184980e-01\n",
      "  -6.46328903e-04  2.42221594e-01]\n",
      " [-7.98849463e-01 -6.89031482e-01 -2.78241813e-01  1.35457277e-01\n",
      "  -1.24193981e-01 -9.32998955e-01 -8.41260135e-01  3.91158670e-01\n",
      "  -1.02847886e+00  2.75516629e+00]\n",
      " [ 8.48502144e-02  4.19577777e-01  1.10323393e+00 -2.75431752e-01\n",
      "   1.67026415e-01  1.83971971e-01 -5.43099284e-01  1.86735094e+00\n",
      "  -7.91648984e-01  2.01821566e+00]\n",
      " [-1.30825400e+00 -1.86662638e+00 -2.70657033e-01  3.88834506e-01\n",
      "   3.08654726e-01  2.43800783e+00  4.88882288e-02 -8.15981984e-01\n",
      "  -2.03726530e+00  8.39460969e-01]\n",
      " [-2.27247000e+00 -1.14123106e+00 -1.03961504e+00  1.90596545e+00\n",
      "   8.95130754e-01  2.64477897e+00 -1.28732681e+00  1.27267706e+00\n",
      "  -1.36292934e-01 -1.75792798e-01]\n",
      " [ 4.80229288e-01 -1.50396907e+00 -1.72886848e-02  1.16906285e+00\n",
      "   1.20440173e+00 -4.13414389e-01 -6.48404002e-01  1.14304805e+00\n",
      "  -1.05518651e+00  2.51416326e-01]\n",
      " [-5.23090124e-01 -1.91511005e-01  7.44455040e-01 -2.15187263e+00\n",
      "   3.75055104e-01  4.97150600e-01  1.28585234e-01  1.06490731e+00\n",
      "  -2.72179842e+00  2.84739828e+00]\n",
      " [-4.23666239e+00 -4.57931423e+00  5.42440116e-01  1.28374600e+00\n",
      "   3.21794438e+00  1.18350732e+00 -2.36569643e+00  2.22052002e+00\n",
      "  -1.51096404e+00 -1.37954259e+00]\n",
      " [ 2.31797546e-01 -4.24804449e-01 -7.56867588e-01  8.80572796e-02\n",
      "  -2.13916630e-01  7.91373849e-01 -1.90623671e-01 -4.02982056e-01\n",
      "  -5.11477709e-01  7.47321725e-01]\n",
      " [-3.32351714e-01 -9.36742574e-02  1.04547121e-01 -7.59546086e-02\n",
      "   2.28221083e+00  6.51864171e-01 -3.63528639e-01  5.25936961e-01\n",
      "  -5.62201619e-01  1.48429656e+00]\n",
      " [-1.47280526e+00  4.94933277e-01 -4.81703281e-02 -4.56669420e-01\n",
      "   9.38505173e-01  7.60485172e-01 -1.89112318e+00 -7.22342283e-02\n",
      "   1.28862858e-02  2.59031713e-01]\n",
      " [-3.80666733e-01  2.32822105e-01 -9.52246368e-01  5.35849690e-01\n",
      "   1.76788783e+00  9.28430378e-01 -2.33047530e-01  1.08895183e-01\n",
      "  -1.43835872e-01  1.22491503e+00]\n",
      " [-3.01655507e+00 -1.72440946e+00 -6.24433577e-01 -9.55758929e-01\n",
      "   4.47246850e-01  3.13904941e-01 -1.21911979e+00  6.31609082e-01\n",
      "  -6.68556690e-01  1.41704345e+00]\n",
      " [-2.61034775e+00  2.02203944e-01  1.44898391e+00 -1.23279560e+00\n",
      "   4.07130909e+00  2.98400974e+00 -1.28748250e+00 -9.28982139e-01\n",
      "  -2.55346441e+00  2.25287294e+00]\n",
      " [ 1.61358893e+00  1.13891280e+00 -9.55187917e-01  3.04255247e-01\n",
      "  -8.56879413e-01  7.57926464e-01 -7.81803071e-01  1.13600969e+00\n",
      "   4.73005205e-01  1.87137258e+00]\n",
      " [-9.18741405e-01 -1.29771411e+00 -1.23470247e+00 -5.04027665e-01\n",
      "   5.14104962e-01  2.11055763e-02 -1.75282523e-01  2.96355098e-01\n",
      "  -4.17323649e-01  1.73035121e+00]\n",
      " [-7.49929011e-01 -1.16035819e+00 -3.48518282e-01  5.41692734e-01\n",
      "   1.69035089e+00  2.16738462e+00 -3.71112645e-01  2.77195275e-01\n",
      "  -1.99651316e-01  9.93460298e-01]\n",
      " [-1.65007496e+00 -9.83390808e-01  2.44428352e-01  1.02570224e+00\n",
      "   2.22652644e-01  6.88400507e-01 -3.13388199e-01 -4.16435823e-02\n",
      "   6.91775262e-01 -2.96680927e-02]\n",
      " [-1.21473992e+00 -1.66912961e+00 -6.81312382e-01  3.80065411e-01\n",
      "   2.00077817e-01 -3.70222986e-01 -8.14641774e-01  5.44855952e-01\n",
      "  -3.73312533e-01 -2.41019160e-01]\n",
      " [-1.81041181e+00 -3.54075134e-01  7.76904404e-01  4.75401729e-01\n",
      "   8.09760749e-01  4.53824669e-01  7.95865238e-01 -7.61036754e-01\n",
      "   5.77648222e-01 -3.86219509e-02]\n",
      " [-1.64070058e+00 -8.20135951e-01 -7.29180455e-01  1.56464267e+00\n",
      "   1.67258871e+00  9.53406692e-01  3.40670459e-02 -3.39320719e-01\n",
      "   2.32827231e-01  1.99563956e+00]\n",
      " [-2.79516757e-01 -7.27307677e-01  1.05789745e+00 -1.06579566e+00\n",
      "   6.73667133e-01  1.93214858e+00 -2.14079380e-01  3.21381986e-01\n",
      "  -7.61506557e-01  1.80692601e+00]\n",
      " [-1.42059994e+00 -2.48748779e-01  4.38778460e-01  1.43516406e-01\n",
      "  -5.36618710e-01  5.54113805e-01 -2.55576164e-01  1.95769910e-02\n",
      "   8.43755364e-01  1.66104317e+00]\n",
      " [-5.59554920e-02 -2.03285530e-01 -1.87857819e+00 -4.57859427e-01\n",
      "  -1.25835985e-01  9.00468826e-01 -2.28419781e-01  1.37751007e+00\n",
      "  -2.02391475e-01  5.86012721e-01]\n",
      " [-1.40343535e+00 -1.27883840e+00 -1.91689089e-01  4.41764265e-01\n",
      "   2.19716549e+00  6.97192788e-01 -1.32943535e+00  5.97903550e-01\n",
      "  -1.72005564e-01  1.11024725e+00]\n",
      " [-2.05780864e+00 -1.59707832e+00  2.90420920e-01  7.72609785e-02\n",
      "   1.39876640e+00 -1.83960438e-01 -1.21225905e+00  4.54039335e-01\n",
      "  -1.25876689e+00  1.65371835e+00]\n",
      " [-1.04797995e+00 -1.09887588e+00 -3.94921601e-01 -1.55910060e-01\n",
      "  -6.88473105e-01  1.25676596e+00 -7.43632376e-01 -3.68358672e-01\n",
      "  -1.81967884e-01  1.57174778e+00]\n",
      " [-1.52058029e+00 -1.00819862e+00  7.71747291e-01 -6.00548148e-01\n",
      "   6.86451554e-01  1.45978189e+00 -7.41900504e-01  7.96410978e-01\n",
      "  -6.86863959e-01  2.04923201e+00]\n",
      " [-8.48357558e-01 -4.19417918e-01 -7.95311272e-01 -3.66557211e-01\n",
      "   6.92299247e-01  5.02576292e-01 -2.09996843e+00  1.33751130e+00\n",
      "  -1.84862828e+00 -3.07783037e-01]\n",
      " [-4.71058667e-01 -1.10374820e+00 -8.77125263e-01  1.45588088e+00\n",
      "  -1.47089690e-01  1.10946620e+00 -5.93896508e-01  4.36005682e-01\n",
      "  -1.13121009e+00  2.12298656e+00]\n",
      " [-2.66890788e+00  7.01181889e-01  7.90493786e-01  4.79831845e-01\n",
      "   7.26725459e-01  1.26197076e+00 -1.66105497e+00  4.17425722e-01\n",
      "   6.42810583e-01  1.18334734e+00]\n",
      " [-5.67642748e-01 -7.86382616e-01 -3.56123298e-01 -5.62492073e-01\n",
      "   9.14952457e-01  2.42742562e+00 -5.34524322e-01  1.19758323e-01\n",
      "   4.15141806e-02  2.34980679e+00]\n",
      " [-8.18271816e-01 -4.21628863e-01 -1.34733200e-01 -1.28967568e-01\n",
      "   1.95327118e-01 -3.73668462e-01 -6.65521026e-01  2.08971828e-01\n",
      "   7.23850071e-01  7.56245911e-01]\n",
      " [-2.48021364e+00 -1.32088685e+00  7.54793346e-01 -2.18900889e-01\n",
      "  -7.66233057e-02  1.03596878e+00 -2.66192287e-01 -6.88916981e-01\n",
      "   1.10877097e+00  6.00644469e-01]\n",
      " [-1.96768701e+00 -1.36979699e+00  5.58924437e-01  3.71133313e-02\n",
      "   2.81906629e+00 -7.95184970e-01 -1.00178540e+00 -9.97376665e-02\n",
      "  -1.93727398e+00  1.90026724e+00]\n",
      " [-1.76719439e+00 -8.55332255e-01  2.94827402e-01 -1.29050088e+00\n",
      "   1.19888306e+00 -1.16490388e+00 -1.26396656e+00 -5.29417813e-01\n",
      "   2.91321665e-01  1.74527740e+00]\n",
      " [-3.29017311e-01 -1.87334269e-01 -1.95014477e-02 -7.75257945e-01\n",
      "   2.62171119e-01  1.06990397e+00 -8.22300762e-02  3.62916216e-02\n",
      "   4.06753533e-02  1.38999248e+00]\n",
      " [-2.02506018e+00 -2.93768430e+00  5.85957646e-01  1.41800308e+00\n",
      "   2.23206425e+00  1.51504111e+00 -7.22859740e-01  1.81048179e+00\n",
      "  -4.44616842e+00  2.98012996e+00]\n",
      " [-2.64883375e+00 -6.17578864e-01 -3.79970050e+00 -1.15110028e+00\n",
      "   1.41386247e+00 -6.24734223e-01  5.63177407e-01 -5.32361805e-01\n",
      "  -2.43703887e-01  2.24045897e+00]\n",
      " [-2.67016149e+00 -4.99032885e-01  9.05861199e-01 -6.83331907e-01\n",
      "   3.10469174e+00  1.78489184e+00 -1.93576312e+00  2.22776985e+00\n",
      "  -2.23974919e+00  1.97968316e+00]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'model1/Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>\", \"<tf.Variable 'model1/conv2d/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref>\", \"<tf.Variable 'model1/conv2d/bias:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'model1/weight2:0' shape=(3136, 256) dtype=float32_ref>\", \"<tf.Variable 'model1/bias2:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'model1/weight3:0' shape=(256, 256) dtype=float32_ref>\", \"<tf.Variable 'model1/bias3:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'model1/weight4:0' shape=(256, 10) dtype=float32_ref>\", \"<tf.Variable 'model1/bias4:0' shape=(10,) dtype=float32_ref>\"] and loss Tensor(\"Mean:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-ac9ffdc38546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_h_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_H\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-113-ac9ffdc38546>\u001b[0m in \u001b[0;36mmodel_h_value\u001b[1;34m(self, h, y)\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.000833\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    405\u001b[0m           \u001b[1;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m           \u001b[1;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'model1/Variable:0' shape=(5, 5, 1, 32) dtype=float32_ref>\", \"<tf.Variable 'model1/conv2d/kernel:0' shape=(5, 5, 32, 64) dtype=float32_ref>\", \"<tf.Variable 'model1/conv2d/bias:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'model1/weight2:0' shape=(3136, 256) dtype=float32_ref>\", \"<tf.Variable 'model1/bias2:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'model1/weight3:0' shape=(256, 256) dtype=float32_ref>\", \"<tf.Variable 'model1/bias3:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'model1/weight4:0' shape=(256, 10) dtype=float32_ref>\", \"<tf.Variable 'model1/bias4:0' shape=(10,) dtype=float32_ref>\"] and loss Tensor(\"Mean:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "\n",
    "### x_data , y_data , dataframe 형태\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "x_data=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    " \n",
    "df1=pd.DataFrame()\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "df1=arr\n",
    "df2=pd.DataFrame()\n",
    "for n in range(0,10):\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "for n in range(0,tr2):\n",
    "    df2[n]=df1[train2[n]]\n",
    "y_data=pd.DataFrame()\n",
    "y_data=df2.transpose()\n",
    "\n",
    "\n",
    "x_data=x_data.values\n",
    "y_data=y_data.values\n",
    "### x_data , y_data , dataframe 형태 넘파이 어레이가 공통적으로 쓰임\n",
    "\n",
    "class CNNModel: \n",
    "    \n",
    "    def __init__(self,sess,name):     \n",
    "\n",
    "        self.sess=sess\n",
    "        self.name=name \n",
    "        \n",
    "    def build_graph(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "            self.Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "            self.keep_rate=tf.placeholder(dtype=tf.float32) \n",
    "            \n",
    "            X_img = tf.reshape(self.X, shape=[-1,28,28,1])\n",
    "\n",
    "            W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "            L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "            L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "            L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "            L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "            W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "            _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "            layer1 = tf.nn.dropout(_layer1 , keep_prob=self.keep_rate)\n",
    "\n",
    "\n",
    "            W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "            _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "            layer2 = tf.nn.dropout(_layer2 , keep_prob=self.keep_rate)\n",
    "\n",
    "\n",
    "            W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "\n",
    "            self.H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "            self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.H , labels=self.Y))\n",
    "\n",
    "            self.train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(self.cost)\n",
    "\n",
    "            self.predict = tf.argmax(self.H,1)\n",
    "            self.correct=tf.equal(self.predict , tf.argmax(self.Y,1)) \n",
    "\n",
    "            self.accuracy=tf.reduce_sum(tf.cast(self.correct , dtype=tf.float32))\n",
    "\n",
    "    \n",
    "    def train_model(self,x,y):\n",
    "\n",
    "        \n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        for step in range(10):\n",
    "            \n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "                batch_x = x[n:n2]\n",
    "                batch_y = y[n:n2]\n",
    "                _,cost_val=self.sess.run([self.train,self.cost], feed_dict={self.X:batch_x,self.Y:batch_y \n",
    "                                                                            ,self.keep_rate:0.5})\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "    def H_value(self,x):\n",
    "        \n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        H_val_arraysum=[]\n",
    "        H_val_arraysumDF=pd.DataFrame()\n",
    "        #H_val_arraysumDF=pd.DataFrame\n",
    "        ran=1\n",
    "        for i in range(ran):\n",
    "            batch_x = x[n:n2]\n",
    "            H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:0.5 }))\n",
    "            H_val_arraysum.extend(H_val) # 리스트방법\n",
    "            \n",
    "            \n",
    "            #H_val_arraysumDF=pd.DataFrame(H_val)\n",
    "            #if i>=2:\n",
    "            #    H_val_arraysumDFresult=pd.merge((H_val_arraysumDF(i)),(H_val_arraysumDF(i+1)),how=\"outer\")\n",
    "            #c=np.vstack((H_val,H_val))\n",
    "            \n",
    "            #H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:1 }))\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "        #print(\"H : {}\".format(H_val))\n",
    "        \n",
    "        #return self.sess.run(self.H, feed_dict={self.X:x , self.keep_rate:1 })\n",
    "        return H_val_arraysum\n",
    "    \n",
    "    \n",
    "    def H_value_sum(self,x,y):\n",
    "        \n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        H_val_arraysum=[]\n",
    "        H_zero = np.zeros((100,10),dtype=np.float32)\n",
    "        ran=420\n",
    "        for i in range(ran):\n",
    "            ### 모델 10개\n",
    "            model_list = [\"m0\",\"m1\"]#,\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "            \n",
    "            for k in model_list:\n",
    "                batch_x = x[n:n2]\n",
    "                batch_y = y[n:n2]\n",
    "                H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:0.5 }))\n",
    "\n",
    "                H_zero=H_zero+H_val\n",
    "            \n",
    "            self.H=H_zero/10\n",
    "            print(self.H)\n",
    "#             _,cost_val=self.sess.run([self.train,self.cost], feed_dict={self.H:H_modelsum , self.Y:batch_y , self.keep_rate:0.5})\n",
    "#             ### 모델 10개 끝\n",
    "            \n",
    "#             ##시험삼아 시작\n",
    "#             self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.H , labels=self.Y))\n",
    "\n",
    "#             self.train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(self.cost)\n",
    "\n",
    "#             self.predict = tf.argmax(self.H,1)\n",
    "#             self.correct=tf.equal(self.predict , tf.argmax(self.Y,1)) \n",
    "\n",
    "#             self.accuracy=tf.reduce_sum(tf.cast(self.correct , dtype=tf.float32))\n",
    "            \n",
    "#             ######    시험삼아 끝\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "            return(self.H)\n",
    "            #print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "        \n",
    "#         def model_sum(self,):\n",
    "            \n",
    "            \n",
    "#                  ### 모델 10개\n",
    "#             model_list = [\"m0\",\"m1\"]#,\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "            \n",
    "#             for k in model_list:\n",
    "#                 batch_x = x[n:n2]\n",
    "#                 batch_y = y[n:n2]\n",
    "#                 H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:0.5 }))\n",
    "\n",
    "#                 H_zero=H_zero+H_val\n",
    "            \n",
    "#             H_modelsum=H_zero/10\n",
    "            \n",
    "#             _,cost_val=self.sess.run([self.train,self.cost], feed_dict={self.H:H_modelsum , self.Y:batch_y , self.keep_rate:0.5})\n",
    "#             ### 모델 10개 끝\n",
    "            \n",
    "    def model_h_value(self,h,y):\n",
    "\n",
    "\n",
    "        batch_y=y[0:100]\n",
    "        \n",
    "        self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.H , labels=self.Y))\n",
    "\n",
    "        self.train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(self.cost)\n",
    "\n",
    "        self.predict = tf.argmax(self.H,1)\n",
    "        self.correct=tf.equal(self.predict , tf.argmax(self.Y,1)) \n",
    "\n",
    "        self.accuracy=tf.reduce_sum(tf.cast(self.correct , dtype=tf.float32))\n",
    "        \n",
    "        cost_val=self.sess.run(self.cost, feed_dict={self.H:h,self.Y:batch_y \n",
    "                                                                        ,self.keep_rate:0.5})\n",
    "\n",
    "        \n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "\n",
    "sess=tf.Session()\n",
    "\n",
    "\n",
    "###모델 10개\n",
    "# model_list = [\"m0\",\"m1\",\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "# model_roof=0\n",
    "# for k in model_list:\n",
    "###모델 10개 끝\n",
    "k=CNNModel(sess,\"model1\")   #객체생성\n",
    "k.build_graph()             #모델생성   m1이 빌드 그래프를 가지고 있다 \n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#m1.train_model(x_data,y_data)\n",
    "\n",
    "#print(m1.H_value(x_data)) # [[-3.2657056   0.75052345 -1.8666681    2.8347716   1.7404464   3.1127691 ][][]...[]]100개\n",
    "\n",
    "\n",
    "\n",
    "self_H=k.H_value_sum(x_data,y_data)\n",
    "\n",
    "\n",
    "k2=CNNModel(sess,\"model2\")\n",
    "k2.model_h_value(self_H,y_data)\n",
    "\n",
    "\n",
    "# 42000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cbd19ae8ddd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[0mcount_of_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCNNModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_of_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_of_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-cbd19ae8ddd4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[0mcount_of_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCNNModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_of_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_of_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "## reset tensorflow graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "class CNNModel: \n",
    "    \n",
    "    def __init__(self,sess,name):     \n",
    "\n",
    "        self.sess=sess\n",
    "        self.name=name \n",
    "        \n",
    "    def build_graph(self):\n",
    "        with tf.variable_scope(self.name):\n",
    "            self.X=tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "            self.Y=tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "            self.keep_rate=tf.placeholder(dtype=tf.float32) \n",
    "            \n",
    "            X_img = tf.reshape(self.X, shape=[-1,28,28,1])\n",
    "\n",
    "            W1=tf.Variable(tf.random_normal([5,5,1,32],stddev=0.01))\n",
    "\n",
    "            L1 = tf.nn.conv2d(X_img,W1,strides=[1,1,1,1], padding=\"SAME\")\n",
    "\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            p1 = tf.nn.max_pool(L1 , ksize=[1,2,2,1] , strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "            L2=tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5,5] , padding=\"SAME\", strides=1 ,activation=tf.nn.relu)\n",
    "\n",
    "            L2=tf.layers.max_pooling2d(inputs=L2 , pool_size=[2,2], padding=\"SAME\" , strides=2)\n",
    "\n",
    "            L2=tf.reshape(L2,shape=[-1,7*7*64])\n",
    "\n",
    "            W2=tf.get_variable(\"weight2\" , shape=[7*7*64,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b2=tf.Variable(tf.random_normal([256]),name=\"bias2\" )\n",
    "\n",
    "            _layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2 )\n",
    "            layer1 = tf.nn.dropout(_layer1 , keep_prob=self.keep_rate)\n",
    "\n",
    "\n",
    "            W3=tf.get_variable(\"weight3\" , shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b3=tf.Variable(tf.random_normal([256]),name=\"bias3\" )\n",
    "\n",
    "            _layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b3 )\n",
    "            layer2 = tf.nn.dropout(_layer2 , keep_prob=self.keep_rate)\n",
    "\n",
    "\n",
    "            W4=tf.get_variable(\"weight4\" , shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4=tf.Variable(tf.random_normal([10]),name=\"bias4\" )\n",
    "\n",
    "            self.H = tf.matmul(layer2,W4)+b4\n",
    "\n",
    "            self.cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.H , labels=self.Y))\n",
    "\n",
    "            self.train = tf.train.AdamOptimizer(learning_rate=0.000833).minimize(self.cost)\n",
    "\n",
    "            self.predict = tf.argmax(self.H,1)\n",
    "            self.correct=tf.equal(self.predict , tf.argmax(self.Y,1)) \n",
    "\n",
    "            self.accuracy=tf.reduce_sum(tf.cast(self.correct , dtype=tf.float32))\n",
    "\n",
    "    \n",
    "    def train_model(self,x,y):\n",
    "        \n",
    "        _,cost_val=self.sess.run([self.train,self.cost], feed_dict={self.X:batch_x,self.Y:batch_y \n",
    "                                                                            ,self.keep_rate:0.5})\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        for step in range(10):\n",
    "            \n",
    "            n=0\n",
    "            n1=100\n",
    "            n2=100\n",
    "\n",
    "            for i in range(420):\n",
    "                batch_x = x[n:n2]\n",
    "                batch_y = y[n:n2]\n",
    "                n=n+n1\n",
    "                n2=n2+n1\n",
    "            print(\"cost : {}\".format(cost_val))\n",
    "            \n",
    "    \n",
    "    def H_value_sum(self,x,y):\n",
    "        \n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "        H_zero = np.zeros((100,10),dtype=np.float32)\n",
    "        ran=420\n",
    "        for i in range(ran):\n",
    "            ### 모델 10개\n",
    "            model_list = [\"m0\",\"m1\"]#,\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "            \n",
    "            for k in model_list:\n",
    "                batch_x = x[n:n2]\n",
    "                batch_y = y[n:n2]\n",
    "                H_val=(self.sess.run(self.H, feed_dict={self.X:batch_x , self.keep_rate:0.5 }))\n",
    "\n",
    "                H_zero=H_zero+H_val\n",
    "            \n",
    "            self.H=H_zero/10\n",
    "            print(self.H)\n",
    "\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "        return(self.H)\n",
    "\n",
    "    ### x_data , y_data , dataframe 형태\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train = pd.read_csv(\"./data/mnist2/train.csv\")\n",
    "test = pd.read_csv(\"./data/mnist2/test.csv\")\n",
    "\n",
    "\n",
    "x_data=train.drop(\"label\", axis=1, inplace=False)\n",
    "train2=train[\"label\"]\n",
    "\n",
    " \n",
    "df1=pd.DataFrame()\n",
    "arr = np.zeros((10,10), dtype=np.int32)\n",
    "df1=arr\n",
    "df2=pd.DataFrame()\n",
    "for n in range(0,10):\n",
    "    df1[n,n]=1\n",
    "    df2[n]=np.arange(10)\n",
    "\n",
    "tr2=int(len(train2))\n",
    "for n in range(0,tr2):\n",
    "    df2[n]=df1[train2[n]]\n",
    "y_data=pd.DataFrame()\n",
    "y_data=df2.transpose()\n",
    "\n",
    "\n",
    "x_data=x_data.values\n",
    "y_data=y_data.values\n",
    "### x_data , y_data , dataframe 형태 넘파이 어레이가 공통적으로 쓰임\n",
    "\n",
    "\n",
    "count_of_models = 10\n",
    "models = [CNNModel(sess,\"model\"+ str(x)) for x in range(count_of_models)]\n",
    "for num in range(count_of_models):\n",
    "    models[num].build_graph()\n",
    "    print(models[num])\n",
    "    models=models.build_graph()\n",
    "\n",
    "    start_roof=0\n",
    "    increase_roof=100\n",
    "    finish_roof=100\n",
    "\n",
    "    H_zero = np.zeros((100,10),dtype=np.float32)\n",
    "    n=0\n",
    "    n1=100\n",
    "    n2=100\n",
    "    for step in range(10):\n",
    "\n",
    "        n=0\n",
    "        n1=100\n",
    "        n2=100\n",
    "\n",
    "        for i in range(420):\n",
    "            batch_x = x[n:n2]\n",
    "            batch_y = y[n:n2]\n",
    "            models[num].train_model\n",
    "            n=n+n1\n",
    "            n2=n2+n1\n",
    "\n",
    "        print(\"cost : {}\".format(cost_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.CNNModel object at 0x000000003C2E57F0>\n"
     ]
    }
   ],
   "source": [
    "print(models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.4025044 ,  3.7187655 , -1.9722697 , -0.46925777, -0.29228485,\n",
       "        7.928941  ,  9.954054  , -0.65744174,  6.9954424 , -0.76876533],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1[41000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -6.6541653   -3.9277194    6.4324713   -7.7255635   -0.88025427\n",
      "  19.678463   -13.832499     0.17511225   4.946245   -17.161434  ]\n",
      "[-3.3270826  -1.9638597   3.2162356  -3.8627818  -0.44012713  9.8392315\n",
      " -6.9162493   0.08755612  2.4731226  -8.580717  ]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "\n",
    "# list 방법\n",
    "\n",
    "print(h1[0]+h1[1])\n",
    "print((h1[0]+h1[1])/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Student:   #클레스 \n",
    "    # 언더바 2개가 뭘 의미한댔지?\n",
    "    def __init__(self,name,kor,eng,math):       # self-> 자바에서 this 함수이기때문에 arg 리스트가 나옴\n",
    "\n",
    "        self.name=name  # 객체가 존재하는한 계속해서 남아있는 객체  자기가 가지고 있는\n",
    "        self.kor=kor\n",
    "        self.eng=eng\n",
    "        self.math=math\n",
    "    \n",
    "    def calc_avg(self):\n",
    "        return (self.kor+self.eng+self.math)/3\n",
    "stu1=Student(\"홍길동\",10,20,30)\n",
    "print(stu1.calc_avg())\n",
    "\n",
    "stu2=Student(\"김길동\",10,20,30)\n",
    "print(stu2.calc_avg())\n",
    "\n",
    "\n",
    "def __init__(self,sess,name,train1,df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'df' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-30fa4fd88c76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'df' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "lst1 = [\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "]\n",
    "a=np.array(lst1)\n",
    "df=pd.DataFrame(a)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [1 2]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.4]\n",
      " [0.6 0.8]]\n",
      "m0\n",
      "m1\n",
      "m2\n",
      "m3\n",
      "m4\n",
      "m5\n",
      "m6\n",
      "m7\n",
      "m8\n",
      "m9\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "lst1 = [\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "]\n",
    "a=np.array(lst1)\n",
    "b=np.array(lst1)\n",
    "print(lst1)\n",
    "display(a)\n",
    "display(b)\n",
    "\n",
    "c=np.vstack((a,b))\n",
    "print(c)\n",
    "display(c)\n",
    "\n",
    "c=np.vstack((c,b))\n",
    "c=np.vstack((c,b))\n",
    "H_val_sum=np.vstack((a,b))\n",
    "display(c)\n",
    "display(H_val_sum)\n",
    "\n",
    "e=a+b\n",
    "\n",
    "print(e/10)\n",
    "\n",
    "model_list = [\"m0\",\"m1\",\"m2\",\"m3\",\"m4\",\"m5\",\"m6\",\"m7\",\"m8\",\"m9\"]\n",
    "\n",
    "for k in model_list:\n",
    "    print(k)\n",
    "\n",
    "    \n",
    "H_zero = np.zeros((100,10),dtype=np.float32)\n",
    "print(H_zero)                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
