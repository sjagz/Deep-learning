{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#실습예제 1 titanic\n",
    "#실습예제 2 admission 대학교 입학 성적\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male\n",
      "0    22.0    7.2500         0         0         1           0         1\n",
      "1    38.0   71.2833         1         0         0           1         0\n",
      "2    26.0    7.9250         0         0         1           1         0\n",
      "3    35.0   53.1000         1         0         0           1         0\n",
      "4    35.0    8.0500         0         0         1           0         1\n",
      "5    30.0    8.4583         0         0         1           0         1\n",
      "6    54.0   51.8625         1         0         0           0         1\n",
      "7     2.0   21.0750         0         0         1           0         1\n",
      "8    27.0   11.1333         0         0         1           1         0\n",
      "9    14.0   30.0708         0         1         0           1         0\n",
      "10    4.0   16.7000         0         0         1           1         0\n",
      "11   58.0   26.5500         1         0         0           1         0\n",
      "12   20.0    8.0500         0         0         1           0         1\n",
      "13   39.0   31.2750         0         0         1           0         1\n",
      "14   14.0    7.8542         0         0         1           1         0\n",
      "15   55.0   16.0000         0         1         0           1         0\n",
      "16    2.0   29.1250         0         0         1           0         1\n",
      "17   30.0   13.0000         0         1         0           0         1\n",
      "18   31.0   18.0000         0         0         1           1         0\n",
      "19   30.0    7.2250         0         0         1           1         0\n",
      "20   35.0   26.0000         0         1         0           0         1\n",
      "21   34.0   13.0000         0         1         0           0         1\n",
      "22   15.0    8.0292         0         0         1           1         0\n",
      "23   28.0   35.5000         1         0         0           0         1\n",
      "24    8.0   21.0750         0         0         1           1         0\n",
      "25   38.0   31.3875         0         0         1           1         0\n",
      "26   30.0    7.2250         0         0         1           0         1\n",
      "27   19.0  263.0000         1         0         0           0         1\n",
      "28   30.0    7.8792         0         0         1           1         0\n",
      "29   30.0    7.8958         0         0         1           0         1\n",
      "..    ...       ...       ...       ...       ...         ...       ...\n",
      "861  21.0   11.5000         0         1         0           0         1\n",
      "862  48.0   25.9292         1         0         0           1         0\n",
      "863  30.0   69.5500         0         0         1           1         0\n",
      "864  24.0   13.0000         0         1         0           0         1\n",
      "865  42.0   13.0000         0         1         0           1         0\n",
      "866  27.0   13.8583         0         1         0           1         0\n",
      "867  31.0   50.4958         1         0         0           0         1\n",
      "868  30.0    9.5000         0         0         1           0         1\n",
      "869   4.0   11.1333         0         0         1           0         1\n",
      "870  26.0    7.8958         0         0         1           0         1\n",
      "871  47.0   52.5542         1         0         0           1         0\n",
      "872  33.0    5.0000         1         0         0           0         1\n",
      "873  47.0    9.0000         0         0         1           0         1\n",
      "874  28.0   24.0000         0         1         0           1         0\n",
      "875  15.0    7.2250         0         0         1           1         0\n",
      "876  20.0    9.8458         0         0         1           0         1\n",
      "877  19.0    7.8958         0         0         1           0         1\n",
      "878  30.0    7.8958         0         0         1           0         1\n",
      "879  56.0   83.1583         1         0         0           1         0\n",
      "880  25.0   26.0000         0         1         0           1         0\n",
      "881  33.0    7.8958         0         0         1           0         1\n",
      "882  22.0   10.5167         0         0         1           1         0\n",
      "883  28.0   10.5000         0         1         0           0         1\n",
      "884  25.0    7.0500         0         0         1           0         1\n",
      "885  39.0   29.1250         0         0         1           1         0\n",
      "886  27.0   13.0000         0         1         0           0         1\n",
      "887  19.0   30.0000         1         0         0           1         0\n",
      "888  30.0   23.4500         0         0         1           1         0\n",
      "889  26.0   30.0000         1         0         0           0         1\n",
      "890  32.0    7.7500         0         0         1           0         1\n",
      "\n",
      "[891 rows x 7 columns]\n",
      "===========\n",
      "[[0.27117366 0.01415106 0.         ... 1.         0.         1.        ]\n",
      " [0.4722292  0.13913574 1.         ... 0.         1.         0.        ]\n",
      " [0.32143755 0.01546857 0.         ... 1.         1.         0.        ]\n",
      " ...\n",
      " [0.37170143 0.04577135 0.         ... 1.         1.         0.        ]\n",
      " [0.32143755 0.0585561  1.         ... 0.         0.         1.        ]\n",
      " [0.39683338 0.01512699 0.         ... 1.         0.         1.        ]]\n",
      "cost:0.790317177772522\n",
      "cost:0.4812646806240082\n",
      "cost:0.4721197485923767\n",
      "cost:0.46895739436149597\n",
      "cost:0.4667634069919586\n",
      "cost:0.4649282395839691\n",
      "cost:0.46333733201026917\n",
      "cost:0.46194887161254883\n",
      "cost:0.46073517203330994\n",
      "cost:0.4596736431121826\n",
      "정확도 =0.7867564558982849\n"
     ]
    }
   ],
   "source": [
    "#1 titanic\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#1. dataloading\n",
    "\n",
    "data=pd.read_csv(\"./data/titanic/titanic_data.csv\" , sep=\",\") #sep 는 csv가 ,로 구분되어있어서 defalt 값??\n",
    "       \n",
    "\n",
    "data_x = data[[\"Sex\",\"Age\",\"Pclass\",\"Fare\"]]\n",
    "data_y = data[\"Survived\"]\n",
    "# data_x 전처리 -> male female 숫자로 ,  pclass 123 가중치가 3이 높고 좋은데 1이 좋은거라 바꿔줌, fare의 크기가 들쭉날쭉\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pclass_dummies = pd.get_dummies(data_x[\"Pclass\"],prefix=\"Pclass\") #원래 갖고있던 값이 열이름 숫자로 감  \n",
    "\n",
    "\n",
    "data_x= data_x.join(pclass_dummies)\n",
    "\n",
    "data_x.drop(\"Pclass\", axis=1 , inplace=True )\n",
    "\n",
    "sex_dummies = pd.get_dummies(data_x[\"Sex\"],prefix=\"Sex\")\n",
    "\n",
    "data_x= data_x.join(sex_dummies)\n",
    "\n",
    "data_x.drop(\"Sex\", axis=1 , inplace=True )\n",
    "\n",
    "print(data_x)\n",
    "print(\"===========\")\n",
    "x_data = MinMaxScaler().fit_transform(data_x.values)\n",
    "y_data = data_y.values.reshape(-1,1) #2차원형태로 만듬\n",
    "print(x_data)\n",
    "\n",
    "X=tf.placeholder(shape=[None,7],dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1],dtype=tf.float32)\n",
    "\n",
    "\n",
    "#weight 와 bias\n",
    "\n",
    "W=tf.Variable(tf.random_normal([7,1]),name=\"weight\" )  \n",
    "b=tf.Variable(tf.random_normal([1]) , name=\"bias\") #덧셈이라 하나만 있어도 되는거 아닌가?\n",
    "\n",
    "#hypothesis\n",
    "\n",
    "logit = tf.matmul(X,W)+b\n",
    "\n",
    "H=tf.sigmoid(logit)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit , labels = Y))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "\n",
    "for step in range(20000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:x_data , Y:y_data})\n",
    "    \n",
    "    if step%2000==0 :\n",
    "        print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "        \n",
    "        \n",
    "predict = tf.cast(H>0.5 ,dtype=tf.float32) \n",
    "correct = tf.equal(predict,Y) \n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "\n",
    "print(\"정확도 ={}\".format(sess.run(accuracy ,feed_dict={X:x_data,Y:y_data} ) ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16       0.75316456 0.         0.         1.         0.        ]\n",
      " [0.72       0.79113924 0.         0.         1.         0.        ]\n",
      " [1.         1.         1.         0.         0.         0.        ]\n",
      " ...\n",
      " [0.56       0.73417722 1.         0.         0.         0.        ]\n",
      " [0.76       0.36708861 0.         0.         0.         1.        ]\n",
      " [0.72       0.4556962  0.         1.         0.         0.        ]]\n",
      "     gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
      "0    380  3.61       0       0       1       0\n",
      "1    660  3.67       0       0       1       0\n",
      "2    800  4.00       1       0       0       0\n",
      "3    640  3.19       0       0       0       1\n",
      "4    520  2.93       0       0       0       1\n",
      "5    760  3.00       0       1       0       0\n",
      "6    560  2.98       1       0       0       0\n",
      "7    400  3.08       0       1       0       0\n",
      "8    540  3.39       0       0       1       0\n",
      "9    700  3.92       0       1       0       0\n",
      "10   800  4.00       0       0       0       1\n",
      "11   440  3.22       1       0       0       0\n",
      "12   760  4.00       1       0       0       0\n",
      "13   700  3.08       0       1       0       0\n",
      "14   700  4.00       1       0       0       0\n",
      "15   480  3.44       0       0       1       0\n",
      "16   780  3.87       0       0       0       1\n",
      "17   360  2.56       0       0       1       0\n",
      "18   800  3.75       0       1       0       0\n",
      "19   540  3.81       1       0       0       0\n",
      "20   500  3.17       0       0       1       0\n",
      "21   660  3.63       0       1       0       0\n",
      "22   600  2.82       0       0       0       1\n",
      "23   680  3.19       0       0       0       1\n",
      "24   760  3.35       0       1       0       0\n",
      "25   800  3.66       1       0       0       0\n",
      "26   620  3.61       1       0       0       0\n",
      "27   520  3.74       0       0       0       1\n",
      "28   780  3.22       0       1       0       0\n",
      "29   520  3.29       1       0       0       0\n",
      "..   ...   ...     ...     ...     ...     ...\n",
      "250  660  3.31       0       0       0       1\n",
      "251  620  3.21       0       0       0       1\n",
      "252  520  4.00       0       1       0       0\n",
      "253  540  3.55       0       0       0       1\n",
      "254  740  3.52       0       0       0       1\n",
      "255  640  3.35       0       0       1       0\n",
      "256  520  3.30       0       1       0       0\n",
      "257  620  3.95       0       0       1       0\n",
      "258  520  3.51       0       1       0       0\n",
      "259  640  3.81       0       1       0       0\n",
      "260  680  3.11       0       1       0       0\n",
      "261  440  3.15       0       1       0       0\n",
      "262  520  3.19       0       0       1       0\n",
      "263  620  3.95       0       0       1       0\n",
      "264  520  3.90       0       0       1       0\n",
      "265  380  3.34       0       0       1       0\n",
      "266  560  3.24       0       0       0       1\n",
      "267  600  3.64       0       0       1       0\n",
      "268  680  3.46       0       1       0       0\n",
      "269  500  2.81       0       0       1       0\n",
      "270  640  3.95       0       1       0       0\n",
      "271  540  3.33       0       0       1       0\n",
      "272  680  3.67       0       1       0       0\n",
      "273  660  3.32       1       0       0       0\n",
      "274  520  3.12       0       1       0       0\n",
      "275  600  2.98       0       1       0       0\n",
      "276  460  3.77       0       0       1       0\n",
      "277  580  3.58       1       0       0       0\n",
      "278  680  3.00       0       0       0       1\n",
      "279  660  3.14       0       1       0       0\n",
      "\n",
      "[280 rows x 6 columns]\n",
      "============\n",
      "     gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
      "280  660  3.94       0       1       0       0\n",
      "281  360  3.27       0       0       1       0\n",
      "282  660  3.45       0       0       0       1\n",
      "283  520  3.10       0       0       0       1\n",
      "284  440  3.39       0       1       0       0\n",
      "285  600  3.31       0       0       0       1\n",
      "286  800  3.22       1       0       0       0\n",
      "287  660  3.70       0       0       0       1\n",
      "288  800  3.15       0       0       0       1\n",
      "289  420  2.26       0       0       0       1\n",
      "290  620  3.45       0       1       0       0\n",
      "291  800  2.78       0       1       0       0\n",
      "292  680  3.70       0       1       0       0\n",
      "293  800  3.97       1       0       0       0\n",
      "294  480  2.55       1       0       0       0\n",
      "295  520  3.25       0       0       1       0\n",
      "296  560  3.16       1       0       0       0\n",
      "297  460  3.07       0       1       0       0\n",
      "298  540  3.50       0       1       0       0\n",
      "299  720  3.40       0       0       1       0\n",
      "300  640  3.30       0       1       0       0\n",
      "301  660  3.60       0       0       1       0\n",
      "302  400  3.15       0       1       0       0\n",
      "303  680  3.98       0       1       0       0\n",
      "304  220  2.83       0       0       1       0\n",
      "305  580  3.46       0       0       0       1\n",
      "306  540  3.17       1       0       0       0\n",
      "307  580  3.51       0       1       0       0\n",
      "308  540  3.13       0       1       0       0\n",
      "309  440  2.98       0       0       1       0\n",
      "..   ...   ...     ...     ...     ...     ...\n",
      "370  540  3.77       0       1       0       0\n",
      "371  680  3.76       0       0       1       0\n",
      "372  680  2.42       1       0       0       0\n",
      "373  620  3.37       1       0       0       0\n",
      "374  560  3.78       0       1       0       0\n",
      "375  560  3.49       0       0       0       1\n",
      "376  620  3.63       0       1       0       0\n",
      "377  800  4.00       0       1       0       0\n",
      "378  640  3.12       0       0       1       0\n",
      "379  540  2.70       0       1       0       0\n",
      "380  700  3.65       0       1       0       0\n",
      "381  540  3.49       0       1       0       0\n",
      "382  540  3.51       0       1       0       0\n",
      "383  660  4.00       1       0       0       0\n",
      "384  480  2.62       0       1       0       0\n",
      "385  420  3.02       1       0       0       0\n",
      "386  740  3.86       0       1       0       0\n",
      "387  580  3.36       0       1       0       0\n",
      "388  640  3.17       0       1       0       0\n",
      "389  640  3.51       0       1       0       0\n",
      "390  800  3.05       0       1       0       0\n",
      "391  660  3.88       0       1       0       0\n",
      "392  600  3.38       0       0       1       0\n",
      "393  620  3.75       0       1       0       0\n",
      "394  460  3.99       0       0       1       0\n",
      "395  620  4.00       0       1       0       0\n",
      "396  560  3.04       0       0       1       0\n",
      "397  460  2.63       0       1       0       0\n",
      "398  700  3.65       0       1       0       0\n",
      "399  600  3.89       0       0       1       0\n",
      "\n",
      "[120 rows x 6 columns]\n",
      "cost:0.9313542246818542\n",
      "cost:0.7705443501472473\n",
      "cost:0.7104769945144653\n",
      "cost:0.6775918006896973\n",
      "cost:0.6547386050224304\n",
      "cost:0.637445330619812\n",
      "cost:0.6240178942680359\n",
      "cost:0.6134752035140991\n",
      "cost:0.605120837688446\n",
      "cost:0.5984349846839905\n",
      "정확도 =0.675000011920929\n"
     ]
    }
   ],
   "source": [
    "#2 주어진 데이터의 70% 를 training 용으로 사용 나머지 30%를 test용으로 사용 \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"./data/admission/admission.csv\" , sep=\",\") #sep 는 csv가 ,로 구분되어있어서 defalt 값??\n",
    "       \n",
    "\n",
    "\n",
    "data_x = data[[\"gre\",\"gpa\",\"rank\"]]\n",
    "data_y = data[\"admit\"]\n",
    "\n",
    "\n",
    "\n",
    "pclass_dummies = pd.get_dummies(data_x[\"rank\"],prefix=\"rank\")\n",
    "\n",
    "data_x= data_x.join(pclass_dummies)\n",
    "\n",
    "data_x.drop(\"rank\", axis=1 , inplace=True )\n",
    "\n",
    "data_x1=data_x[0:int(len(data_x)/10*7)]\n",
    "data_x2=data_x[int(len(data_x)/10*7):int(len(data_x))]\n",
    "\n",
    "data_y1=data_y[0:int(len(data_y)/10*7)]\n",
    "data_y2=data_y[int(len(data_y)/10*7):int(len(data_y))]\n",
    "\n",
    "x_data = MinMaxScaler().fit_transform(data_x1.values)\n",
    "x_data2 = MinMaxScaler().fit_transform(data_x2.values)\n",
    "print(x_data)\n",
    "print(data_x1)\n",
    "print(\"============\")\n",
    "print(data_x2)\n",
    "\n",
    "\n",
    "# print(x_data)\n",
    "# print(x_data[0][4])\n",
    "# #print(x_data[0,int(len(x_data)/10*7)])\n",
    "\n",
    "y_data = data_y1.values.reshape(-1,1) #2차원형태로 만듬\n",
    "y_data2 = data_y2.values.reshape(-1,1)\n",
    "\n",
    "X=tf.placeholder(shape=[None,6],dtype=tf.float32)\n",
    "Y=tf.placeholder(shape=[None,1],dtype=tf.float32)\n",
    "\n",
    "W=tf.Variable(tf.random_normal([6,1]),name=\"weight\" )  \n",
    "b=tf.Variable(tf.random_normal([1]) , name=\"bias\")\n",
    "\n",
    "logit = tf.matmul(X,W)+b\n",
    "\n",
    "H=tf.sigmoid(logit)\n",
    "\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit , labels = Y))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#학습\n",
    "\n",
    "for step in range(20000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:x_data , Y:y_data})\n",
    "    \n",
    "    if step%2000==0 :\n",
    "        print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "\n",
    "\n",
    "predict = tf.cast(H>0.5 ,dtype=tf.float32) \n",
    "correct = tf.equal(predict,Y) \n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "\n",
    "print(\"정확도 ={}\".format(sess.run(accuracy ,feed_dict={X:x_data2,Y:y_data2} ) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573147\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast_11:0' shape=(400,) dtype=float32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data=pd.read_csv(\"./data/admission/admission.csv\" , sep=\",\") #sep 는 csv가 ,로 구분되어있어서 defalt 값??\n",
    "       \n",
    "data_x = data[[\"gre\",\"gpa\",\"rank\"]]\n",
    "data_y = data[\"admit\"]\n",
    "\n",
    "pclass_dummies = pd.get_dummies(data_x[\"rank\"],prefix=\"rank\")\n",
    "data_x= data_x.join(pclass_dummies)\n",
    "data_x.drop(\"rank\", axis=1 , inplace=True )\n",
    "\n",
    "logit = sm.Logit(data_y,data_x)#모델생성 #레이블 먼저 넣고 그다음 값 \n",
    "\n",
    "result=logit.fit()#학습과정\n",
    "\n",
    "result1=result.predict(data_x)#예측\n",
    "\n",
    "\n",
    "\n",
    "predict = tf.cast(result1>0.5 ,dtype=tf.float32) \n",
    "\n",
    "display(predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:2.4918768405914307\n",
      "cost:0.5253993272781372\n",
      "cost:0.4174984395503998\n",
      "cost:0.36370161175727844\n",
      "cost:0.32907724380493164\n",
      "cost:0.30417177081108093\n",
      "cost:0.28505632281303406\n",
      "cost:0.26973846554756165\n",
      "cost:0.25708216428756714\n",
      "cost:0.24637995660305023\n",
      "정확도=0.9803500175476074\n",
      "height :180\n",
      "weight : 100\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"./data/bmi/bmi.csv\" , sep=\",\" , skiprows = 3) #sep 는 csv가 ,로 구분되어있어서 defalt 값??\n",
    "       #결치값 제거\n",
    "\n",
    "data = data.dropna(how=\"any\")\n",
    "\n",
    "df_x = data[[\"height\",\"weight\"]]\n",
    "df_y = data[\"label\"]\n",
    "df_x2=df_x\n",
    "\n",
    "# df_y 를 분류해야함 100  010 001 , 0 1 2\n",
    "\n",
    "y_data=tf.one_hot(df_y , 3)\n",
    "\n",
    "sess=tf.Session()\n",
    "y_data = sess.run(y_data)\n",
    "\n",
    "#print(sess.run(y_data)) = minmax 한거랑 똑같\n",
    "scaler= MinMaxScaler()\n",
    "x_data = scaler.fit_transform(df_x.values)\n",
    "\n",
    "# print(len(df_x2))\n",
    "# # df_x2.loc[len(df_x2)]=[180,80]\n",
    "\n",
    "# # print(df_x2)\n",
    "\n",
    "# # x_data2 = MinMaxScaler().fit_transform(df_x2.values)\n",
    "\n",
    "# print(x_data2)\n",
    "# print(len(df_x2))\n",
    "# print(x_data2[len(df_x2)-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(shape=[None,2],dtype = tf.float32  ) #행 숫자는 무상관\n",
    "Y = tf.placeholder(shape=[None,3],dtype = tf.float32  )\n",
    "\n",
    "W= tf.Variable(tf.random_normal([2,3]), name=\"weight\"  )\n",
    "b= tf.Variable(tf.random_normal([3]),name=\"bias\")\n",
    "\n",
    "\n",
    "logit = tf.matmul(X,W)+b\n",
    "H=tf.nn.softmax(logit)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2( logits=logit , labels=Y ))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(10000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:x_data,Y:y_data} )\n",
    "    if step%1000 == 0 :\n",
    "        print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "        \n",
    "predict=tf.argmax(H , 1)  \n",
    "correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "accuracy=tf.reduce_mean(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "print(\"정확도={}\".format(sess.run(accuracy, feed_dict={X:x_data,Y:y_data} )) )\n",
    "\n",
    "\n",
    "x1=int(input('height :'))\n",
    "x2=int(input('weight : '))\n",
    "df_x2.loc[len(df_x2)]=[x1,x2]\n",
    "\n",
    "\n",
    "\n",
    "x_data2 = MinMaxScaler().fit_transform(df_x2.values)\n",
    "\n",
    "\n",
    "\n",
    "print(sess.run(predict, feed_dict={X:[x_data2[len(df_x2)-1]]} ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:1.2652949094772339\n",
      "cost:0.5033912658691406\n",
      "cost:0.40818604826927185\n",
      "cost:0.3580704629421234\n",
      "cost:0.3251631259918213\n",
      "cost:0.3012332022190094\n",
      "cost:0.28273701667785645\n",
      "cost:0.2678440809249878\n",
      "cost:0.25549376010894775\n",
      "cost:0.24502187967300415\n",
      "정확도=0.9803500175476074\n",
      "height :180\n",
      "weight : 75\n",
      "[[0.75       0.88888889]]\n",
      "[1]\n",
      "[[0.02429484 0.7353327  0.2403725 ]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8173477cb794>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_data2\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_data2\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"./data/bmi/bmi.csv\" , sep=\",\" , skiprows = 3) #sep 는 csv가 ,로 구분되어있어서 defalt 값??\n",
    "       #결치값 제거\n",
    "\n",
    "data = data.dropna(how=\"any\")\n",
    "\n",
    "df_x = data[[\"height\",\"weight\"]]\n",
    "df_y = data[\"label\"]\n",
    "df_x2=df_x\n",
    "\n",
    "# df_y 를 분류해야함 100  010 001 , 0 1 2\n",
    "\n",
    "y_data=tf.one_hot(df_y , 3)\n",
    "\n",
    "sess=tf.Session()\n",
    "y_data = sess.run(y_data)\n",
    "\n",
    "#print(sess.run(y_data)) = minmax 한거랑 똑같\n",
    "scaler= MinMaxScaler()\n",
    "x_data = scaler.fit_transform(df_x.values)\n",
    "\n",
    "# print(len(df_x2))\n",
    "# # df_x2.loc[len(df_x2)]=[180,80]\n",
    "\n",
    "# # print(df_x2)\n",
    "\n",
    "# # x_data2 = MinMaxScaler().fit_transform(df_x2.values)\n",
    "\n",
    "# print(x_data2)\n",
    "# print(len(df_x2))\n",
    "# print(x_data2[len(df_x2)-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = tf.placeholder(shape=[None,2],dtype = tf.float32  ) #행 숫자는 무상관\n",
    "Y = tf.placeholder(shape=[None,3],dtype = tf.float32  )\n",
    "\n",
    "W= tf.Variable(tf.random_normal([2,3]), name=\"weight\"  )\n",
    "b= tf.Variable(tf.random_normal([3]),name=\"bias\")\n",
    "\n",
    "\n",
    "logit = tf.matmul(X,W)+b\n",
    "H=tf.nn.softmax(logit)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2( logits=logit , labels=Y ))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "for step in range(10000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:x_data,Y:y_data} )\n",
    "    if step%1000 == 0 :\n",
    "        print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "        \n",
    "predict=tf.argmax(H , 1)  \n",
    "correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "accuracy=tf.reduce_mean(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "print(\"정확도={}\".format(sess.run(accuracy, feed_dict={X:x_data,Y:y_data} )) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1=int(input('height :'))\n",
    "x2=int(input('weight : '))\n",
    "\n",
    "np=np.array([[x1,x2]])\n",
    "\n",
    "\n",
    "x_data2 = scaler.transform(np) \n",
    "\n",
    "\n",
    "#scaler= MinMaxScaler()\n",
    "#x_data = scaler.fit_transform(df_x.values)\n",
    "#x_data2 = scaler.transform(np)  \n",
    "# 위 3줄처럼 적으면 scaler가 민맥스 최소 최대값을 들고있어서 \n",
    "\n",
    "\n",
    "\n",
    "print(x_data2)\n",
    "\n",
    "\n",
    "print(sess.run(predict, feed_dict={X:x_data2} ))\n",
    "print(sess.run(H, feed_dict={X:x_data2} ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height    188\n",
      "weight     71\n",
      "Name: 0, dtype: int64\n",
      "[[0.85  ]\n",
      " [0.5125]\n",
      " [0.725 ]\n",
      " ...\n",
      " [0.375 ]\n",
      " [0.8625]\n",
      " [0.275 ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"./data/bmi/bmi.csv\" , sep=\",\" , skiprows = 3) #sep 는 csv가 ,로 구분되어있어서 defalt 값??\n",
    "       #결치값 제거\n",
    "\n",
    "data = data.dropna(how=\"any\")\n",
    "\n",
    "df_x = data[[\"height\",\"weight\"]]\n",
    "df_y = data[\"label\"]\n",
    "df_x2=df_x\n",
    "\n",
    "# df_y 를 분류해야함 100  010 001 , 0 1 2\n",
    "\n",
    "y_data=tf.one_hot(df_y , 3)\n",
    "\n",
    "sess=tf.Session()\n",
    "y_data = sess.run(y_data)\n",
    "\n",
    "#print(sess.run(y_data)) = minmax 한거랑 똑같\n",
    "scaler= MinMaxScaler()\n",
    "x_data = scaler.fit_transform(df_x.values)\n",
    "\n",
    "print(df_x.loc[0])\n",
    "\n",
    "\n",
    "print(x_data[:,:1])\n",
    "print(y_data[:,:1])\n",
    "plt.scatter(x_data[:,:1],y_data[:,:1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "cost: 1.9363421201705933\n",
      "cost: 0.9512214660644531\n",
      "cost: 0.6556088328361511\n",
      "cost: 0.8562511205673218\n",
      "cost: 0.3121143877506256\n",
      "cost: 0.5650436282157898\n",
      "cost: 0.6213122606277466\n",
      "cost: 0.41575005650520325\n",
      "cost: 0.5824372172355652\n",
      "cost: 0.46996399760246277\n",
      "정확도:0.900600016117096\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#mnist 숫자 알아내는 것 \n",
    "#입력데이터 0~9         4   28픽셀 , 28픽셀   픽셀데이터 \n",
    "\n",
    "#y축데이터 -> 어떤숫자인지 표시 10개 중 1개\n",
    "#입력데이터 -> 픽셀 값  x축 값 700여개\n",
    "#원래 이미지 데이터는 3차원 데이터를 흑백 -> 2차원 데이터를 다시 1차원으로 변환\n",
    "# 약 5만 5천개의 이미지를 입력\n",
    "\n",
    "# x 파라미터 shape => 55000 , (28*28) (784개) 트레이닝 데이터\n",
    "# y측 레이블의 shape 55000 , 10\n",
    "\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#데이터 로딩\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) #학습용으로 나온 데이터고 그냥 읽어내면됨\n",
    "#원핫 처리없이 기본 데이터가 원핫으로 처리되어서 나옴 즉 데이터 전처리가 불필요\n",
    "\n",
    "#mnist.train.num_examples\n",
    "\n",
    "plt.imshow(mnist.train.images[0].reshape(28,28),cmap=\"Greys\",interpolation=\"nearest\"  )\n",
    "\n",
    "#interpolation 뭔뜻?  2차배열로 바꿈 원래 이미지형태로\n",
    "\n",
    "\n",
    "sess=tf.Session()\n",
    "#sess.run(tf.argmax(mnist.train.labels[0]) #1차 배열을 2차배열로 만들어야 argmax 됨\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2.placeholder\n",
    "\n",
    "X=tf.placeholder(shape=[None,784],dtype=tf.float32 )\n",
    "Y=tf.placeholder(shape=[None,10],dtype=tf.float32 )\n",
    "\n",
    "\n",
    "#3.weight\n",
    "\n",
    "W=tf.Variable(tf.random_normal([784,10]), name=\"weight\" )\n",
    "b=tf.Variable(tf.random_normal([10]), name=\"bias\"  )\n",
    "\n",
    "\n",
    "logit=tf.matmul(X,W)+b\n",
    "H=tf.nn.softmax(logit)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2( logits=logit , labels=Y ))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size=100\n",
    "train_epoch=30\n",
    "avg_cost = 0\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter=int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x , batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _,cost_val=sess.run([train,cost],feed_dict={X:batch_x,Y:batch_y})\n",
    "\n",
    "       # avg_cost = (cost_val / num_of_iter)\n",
    "    if step%3 == 0:\n",
    "        print(\"cost: {}\".format(cost_val))\n",
    "       # print(\"full cost:{}\".format(avg_cost))\n",
    "        \n",
    "#acuracy\n",
    "\n",
    "predict = tf.argmax(H,1)\n",
    "correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "accuracy=tf.reduce_mean(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images,Y:mnist.test.labels})) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "============\n",
      "55000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#데이터 로딩\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True) #학습용으로 나온 데이터고 그냥 읽어내면됨\n",
    "#원핫 처리없이 기본 데이터가 원핫으로 처리되어서 나옴 즉 데이터 전처리가 불필요\n",
    "\n",
    "#mnist.train.num_examples\n",
    "\n",
    "plt.imshow(mnist.train.images[0].reshape(28,28),cmap=\"Greys\",interpolation=\"nearest\"  )\n",
    "\n",
    "#interpolation 뭔뜻?  2차배열로 바꿈 원래 이미지형태로\n",
    "\n",
    "\n",
    "sess=tf.Session()\n",
    "#sess.run(tf.argmax(mnist.train.labels[0]) #1차 배열을 2차배열로 만들어야 argmax 됨\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2.placeholder\n",
    "\n",
    "X=tf.placeholder(shape=[None,784],dtype=tf.float32 )\n",
    "Y=tf.placeholder(shape=[None,10],dtype=tf.float32 )\n",
    "\n",
    "\n",
    "#3.weight\n",
    "\n",
    "W=tf.Variable(tf.random_normal([784,10]), name=\"weight\" )\n",
    "b=tf.Variable(tf.random_normal([10]), name=\"bias\"  )\n",
    "\n",
    "\n",
    "logit=tf.matmul(X,W)+b\n",
    "H=tf.nn.softmax(logit)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2( logits=logit , labels=Y ))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size=100\n",
    "train_epoch=30\n",
    "\n",
    "print(\"============\")\n",
    "print(mnist.train.num_examples)\n",
    "# for step in range(train_epoch):\n",
    "#     num_of_iter=int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    \n",
    "#     for i in range(num_of_iter):\n",
    "#         batch_x , batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "#         _,cost_val=sess.run([train,cost],feed_dict={X:batch_x,Y:batch_y})\n",
    "\n",
    "        \n",
    "#     if step%3 == 0:\n",
    "#         print(\"cost: {}\".format(cost_val))\n",
    "        \n",
    "# #acuracy\n",
    "\n",
    "# predict = tf.argmax(H,1)\n",
    "# correct=tf.equal(predict , tf.argmax(Y,1)) \n",
    "\n",
    "# accuracy=tf.reduce_mean(tf.cast(correct , dtype=tf.float32))\n",
    "\n",
    "# print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images,Y:mnist.test.labels})) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "data_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
