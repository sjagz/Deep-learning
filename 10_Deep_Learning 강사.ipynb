{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost : 0.7425564527511597\n",
      "Cost : 0.6954735517501831\n",
      "Cost : 0.6933144927024841\n",
      "Cost : 0.6931617856025696\n",
      "Cost : 0.6931485533714294\n",
      "Cost : 0.6931473016738892\n",
      "Cost : 0.6931471824645996\n",
      "Cost : 0.6931471824645996\n",
      "Cost : 0.6931471824645996\n",
      "Cost : 0.6931471824645996\n",
      "정확도 : 0.25\n"
     ]
    }
   ],
   "source": [
    "## AND 연산과 OR 연산에 학습이 가능한지를 알아보아요!\n",
    "## Logistic Regression\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set\n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "# y_data = [[0],[0],[0],[1]]  # AND Operation\n",
    "# y_data = [[0],[1],[1],[1]]  # OR operation\n",
    "y_data = [[0],[1],[1],[0]]  # XOR operation\n",
    "# 2. placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "# 3. Weight & bias\n",
    "W = tf.Variable(tf.random_normal([2,1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "# 4. Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "# 5. Cost function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                                              labels=Y))\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# 7. session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))\n",
    "# 9. accuracy\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, \n",
    "                                 feed_dict={X:x_data, \n",
    "                                            Y:y_data})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost : 4.474294662475586\n",
      "Cost : 0.00020849495194852352\n",
      "Cost : 0.00012202482321299613\n",
      "Cost : 8.729781984584406e-05\n",
      "Cost : 6.843328446848318e-05\n",
      "Cost : 5.6556673371233046e-05\n",
      "Cost : 4.835074651055038e-05\n",
      "Cost : 4.2337407649029046e-05\n",
      "Cost : 3.7725625588791445e-05\n",
      "Cost : 3.408309567021206e-05\n",
      "정확도 : 1.0\n"
     ]
    }
   ],
   "source": [
    "### Multiple layer를 이용한 XOR문제 해결\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1. training data set\n",
    "x_data = [[0,0],\n",
    "          [0,1],\n",
    "          [1,0],\n",
    "          [1,1]]\n",
    "y_data = [[0],[1],[1],[0]]\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W1 = tf.Variable(tf.random_normal([2,256]), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,512]), name=\"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([512]), name=\"bias2\")\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,1]), name=\"weight3\")\n",
    "b3 = tf.Variable(tf.random_normal([1]), name=\"bias3\")\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2,W3) + b3\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# Cost function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, \n",
    "                                                              labels=Y))\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train,cost], feed_dict={X:x_data,\n",
    "                                                    Y:y_data})\n",
    "    if step % 3000 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))\n",
    "        \n",
    "# accuracy\n",
    "predict = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy, \n",
    "                                 feed_dict={X:x_data, \n",
    "                                            Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Cost : 6.9437575340271\n",
      "Cost : 2.1060941219329834\n",
      "Cost : 1.7643548250198364\n",
      "Cost : 1.4535472393035889\n",
      "Cost : 1.4440171718597412\n",
      "Cost : 1.5990337133407593\n",
      "Cost : 0.9881365895271301\n",
      "Cost : 0.8555994629859924\n",
      "Cost : 0.906221330165863\n",
      "Cost : 0.734693169593811\n",
      "정확도 : 0.8335999846458435\n"
     ]
    }
   ],
   "source": [
    "### MNIST - Multinomial Classification\n",
    "### learning_rate = 0.1 => 90%\n",
    "### learning_rate = 0.01 => 83%\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "### 1. Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "### 2. Placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# 3. Weight & bias\n",
    "W = tf.Variable(tf.random_normal([784,10]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([10]), name=\"bias\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.nn.softmax(logit)   # 확률값으로 결과를 얻기위해\n",
    "\n",
    "# 5. cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, \n",
    "                                                                 labels=Y))\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# 7. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "train_epoch = 30\n",
    "batch_size = 100 # 한번에 읽어들일 데이터의 크기\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost],feed_dict={X:batch_x,\n",
    "                                                      Y:batch_y})\n",
    "    if step % 3 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val)) \n",
    "        \n",
    "# accuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# 정확도 출력\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,feed_dict={X:mnist.test.images,\n",
    "                                                    Y:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <timed exec>:14: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\envs\\data_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Cost : 0.4852394759654999\n",
      "Cost : 0.14110228419303894\n",
      "Cost : 0.06159446761012077\n",
      "Cost : 0.09411464631557465\n",
      "Cost : 0.07455004751682281\n",
      "Cost : 0.07074318826198578\n",
      "Cost : 0.07937780022621155\n",
      "Cost : 0.0967945009469986\n",
      "Cost : 0.03138711303472519\n",
      "Cost : 0.01914205402135849\n",
      "정확도 : 0.9821000099182129\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### MNIST - Neural Network ( wide & deep )\n",
    "### Wall time: 1min 2s\n",
    "### Wall time: 1min 19s\n",
    "###         => Sigmoid => ReLU로 변경\n",
    "###         => Xavier initialization을 도입해서 초기 W값 지정\n",
    "###         => overfitting을 피하기 위해 dropout을 도입\n",
    "### learning_rate = 0.1 => 91.7% => X => 97% => 98%\n",
    "### learning_rate = 0.01 => 86% => 93.9% => 95.8%\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "### 1. Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "### 2. Placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# 3. Weight & bias\n",
    "keep = tf.placeholder(dtype=tf.float32)\n",
    "W1 = tf.get_variable(\"weight1\", shape=[784,256], \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name=\"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep)\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256,512], \n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]), name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob=keep)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[512,10], \n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "\n",
    "# 4. Hypothesis\n",
    "H = tf.matmul(layer2,W3) + b3\n",
    "# H = tf.nn.softmax(logit)\n",
    "\n",
    "# 5. cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H, \n",
    "                                                                 labels=Y))\n",
    "# 6. train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 7. session & 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 8. 학습\n",
    "train_epoch = 30\n",
    "batch_size = 100 # 한번에 읽어들일 데이터의 크기\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost],feed_dict={X:batch_x,\n",
    "                                                      Y:batch_y,\n",
    "                                                      keep:0.7})\n",
    "    if step % 3 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val)) \n",
    "        \n",
    "# accuracy\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "# 정확도 출력\n",
    "print(\"정확도 : {}\".format(sess.run(accuracy,feed_dict={X:mnist.test.images,\n",
    "                                                    Y:mnist.test.labels,\n",
    "                                                    keep:1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.4250777 , 0.        , 0.16436276, 0.        , 0.        ,\n",
       "          0.792048  , 0.2986828 , 0.7521249 , 0.6876709 , 0.24627063,\n",
       "          0.        , 0.        , 1.3901913 , 0.41779146, 0.14644326,\n",
       "          0.        , 0.7909863 , 0.        , 0.2326116 , 0.        ,\n",
       "          0.        , 0.        , 0.        , 0.7903572 , 0.21789292,\n",
       "          0.24387664, 0.        , 0.        , 0.        , 0.87844276,\n",
       "          0.        , 0.48172048],\n",
       "         [1.8955672 , 0.        , 0.2686035 , 0.        , 0.        ,\n",
       "          0.9835886 , 0.45475066, 0.9452087 , 0.9789232 , 0.26890695,\n",
       "          0.        , 0.        , 1.6595421 , 0.33861655, 0.2043468 ,\n",
       "          0.        , 1.0016553 , 0.        , 0.46489787, 0.        ,\n",
       "          0.        , 0.        , 0.        , 1.0222609 , 0.2554988 ,\n",
       "          0.3396501 , 0.        , 0.        , 0.        , 0.98384947,\n",
       "          0.        , 0.5204728 ],\n",
       "         [0.9143663 , 0.        , 0.        , 0.        , 0.        ,\n",
       "          0.        , 1.4075538 , 1.2986302 , 1.1684136 , 0.        ,\n",
       "          0.43757996, 0.4977361 , 1.2121496 , 0.        , 1.0648192 ,\n",
       "          1.1987587 , 0.68424207, 0.59458673, 1.4010555 , 0.        ,\n",
       "          0.04248482, 0.        , 0.        , 0.23046908, 0.6765007 ,\n",
       "          0.6863481 , 0.        , 0.39564228, 0.85323113, 0.82974946,\n",
       "          0.37333685, 1.0146858 ]],\n",
       "\n",
       "        [[2.8365464 , 0.        , 0.47708505, 0.        , 0.        ,\n",
       "          1.3666698 , 0.7668865 , 1.3313764 , 1.5614282 , 0.3141796 ,\n",
       "          0.        , 0.        , 2.1982439 , 0.18026686, 0.3201539 ,\n",
       "          0.        , 1.4229937 , 0.        , 0.9294701 , 0.        ,\n",
       "          0.04206419, 0.        , 0.        , 1.4860682 , 0.33071065,\n",
       "          0.53119713, 0.        , 0.        , 0.0394206 , 1.194663  ,\n",
       "          0.        , 0.59797746],\n",
       "         [3.307036  , 0.        , 0.5813259 , 0.        , 0.        ,\n",
       "          1.5582105 , 0.92295426, 1.5244602 , 1.8526806 , 0.33681592,\n",
       "          0.        , 0.        , 2.4675946 , 0.10109198, 0.37805742,\n",
       "          0.04349232, 1.6336627 , 0.        , 1.1617563 , 0.        ,\n",
       "          0.20459485, 0.        , 0.        , 1.717972  , 0.36831647,\n",
       "          0.6269707 , 0.        , 0.        , 0.07991171, 1.3000696 ,\n",
       "          0.        , 0.63672984],\n",
       "         [1.5850879 , 0.        , 0.08123636, 0.        , 0.        ,\n",
       "          0.        , 2.3021462 , 2.1025856 , 1.7553506 , 0.        ,\n",
       "          0.9082111 , 0.64066553, 1.8707957 , 0.        , 1.7754977 ,\n",
       "          1.9796965 , 0.957399  , 0.9753251 , 2.379006  , 0.        ,\n",
       "          0.36540377, 0.        , 0.        , 0.2889338 , 1.0702649 ,\n",
       "          0.9329142 , 0.        , 0.6933726 , 1.1893376 , 1.2750947 ,\n",
       "          0.68450457, 1.4604154 ]],\n",
       "\n",
       "        [[1.7344306 , 0.        , 0.56242263, 0.89240646, 0.        ,\n",
       "          0.40204465, 0.3620137 , 0.        , 1.5260353 , 0.        ,\n",
       "          0.6093092 , 0.34304065, 0.        , 0.        , 0.        ,\n",
       "          0.3728907 , 0.5027946 , 1.2413969 , 1.4226133 , 0.        ,\n",
       "          2.866992  , 2.7567112 , 0.        , 0.97030807, 0.        ,\n",
       "          0.47187808, 0.        , 0.        , 0.52026665, 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [1.9690293 , 0.        , 0.65688545, 0.9920656 , 0.        ,\n",
       "          0.45577484, 0.42316675, 0.        , 1.7170173 , 0.        ,\n",
       "          0.70645964, 0.37709248, 0.        , 0.        , 0.        ,\n",
       "          0.43463194, 0.55989695, 1.4035252 , 1.6235585 , 0.        ,\n",
       "          3.250506  , 3.1224911 , 0.        , 1.0868657 , 0.        ,\n",
       "          0.5228121 , 0.        , 0.        , 0.5777576 , 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [1.2812307 , 0.15473221, 1.7395164 , 0.        , 0.        ,\n",
       "          0.25017285, 1.1448932 , 0.9278405 , 0.01638146, 0.        ,\n",
       "          1.5110471 , 0.        , 0.31542778, 0.        , 1.0696137 ,\n",
       "          1.089351  , 0.        , 0.50067025, 1.664536  , 1.0572504 ,\n",
       "          1.810059  , 1.5257497 , 0.        , 0.        , 0.3330837 ,\n",
       "          0.        , 0.2094875 , 0.59945494, 0.        , 0.18282285,\n",
       "          0.74699575, 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# image의 shape => (1,3,3,1) => (이미지개수,가로,세로,color)\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]\n",
    "                  ]], dtype=np.float32)\n",
    "image = tf.reshape(image, [1,3,3,1])\n",
    "\n",
    "# filter의 shape => (2,2,1,3) => (가로,세로,color,필터개수)\n",
    "# W = np.array([[[[1,10,-1]],\n",
    "#                [[1,10,-1]]],\n",
    "#                [[[1,10,-1]],\n",
    "#                [[1,10,-1]]]], dtype=np.float32)\n",
    "# 이미지와 filter를 이용해서 convolution을 생성\n",
    "# conv2d = tf.nn.conv2d(image, W, strides=[1,1,1,1],\n",
    "#                      padding=\"VALID\")\n",
    "# conv2d = tf.nn.relu(conv2d)\n",
    "conv2d = tf.layers.conv2d(inputs=image, \n",
    "                          filters=32,\n",
    "                          strides=1,\n",
    "                          activation=tf.nn.relu,\n",
    "                          kernel_size=[2,2],\n",
    "                          padding=\"SAME\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[4.],\n",
       "         [3.]],\n",
       "\n",
       "        [[2.],\n",
       "         [2.]]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# image => (1,2,2,1)\n",
    "images = np.array([\n",
    "                    [\n",
    "                        [\n",
    "                            [4],\n",
    "                            [3]\n",
    "                        ],\n",
    "                        [\n",
    "                            [1],\n",
    "                            [2]\n",
    "                        ]\n",
    "                    ]\n",
    "                  ], dtype=np.float32)\n",
    "images.shape\n",
    "pool = tf.nn.max_pool(images,ksize=[1,2,2,1],\n",
    "                      strides=[1,1,1,1], padding=\"SAME\")\n",
    "sess.run(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### MNIST 이미지 1장으로 Convolution과 MAX Pooling처리\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 1. Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "## 2. 처음 1장의 이미지만 가지고 해 보아요!!\n",
    "img = mnist.train.images[0]\n",
    "# plt.imshow(img.reshape(28,28), cmap=\"Greys\")\n",
    "# plt.show()\n",
    "## 3. Convolution\n",
    "## 원본데이터의 형태부터 변경해줘야 해요!\n",
    "img = tf.reshape(img, shape=[-1,28,28,1])\n",
    "## 필터를 정의해줘야 해요!! ( 필터크기 :3x3, 필터개수:5)\n",
    "W = tf.Variable(tf.random_normal([3,3,1,5]))\n",
    "conv2d = tf.nn.conv2d(img, W, strides=[1,2,2,1], \n",
    "                      padding=\"SAME\")\n",
    "# tf.nn.relu\n",
    "conv2d = tf.nn.relu(conv2d)\n",
    "# MAX Pooling (sub sampling)\n",
    "pool = tf.nn.max_pool(conv2d, ksize=[1,2,2,1], \n",
    "                      strides=[1,2,2,1], padding=\"SAME\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "result = sess.run(pool)\n",
    "result.shape # (1, 14, 14, 5) => conv2d\n",
    "             # (1, 7, 7, 5)  \n",
    "\n",
    "## 결과이미지를 출력해보기 위해서 데이터 처리를 약간 진행\n",
    "## 결과이미지의 axes를 변경해서 (5,14,14,1)\n",
    "result = np.swapaxes(result,0,3)\n",
    "fig, axes = plt.subplots(1,5)\n",
    "for idx, t_img in enumerate(result):\n",
    "    axes[idx].imshow(t_img.reshape(7,7), cmap=\"Greys\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Cost : 0.15059329569339752\n",
      "Cost : 0.2369040846824646\n",
      "Cost : 0.04389926418662071\n",
      "Cost : 0.23594258725643158\n",
      "Cost : 0.05481968820095062\n",
      "Cost : 0.007061885204166174\n",
      "Cost : 0.07312717288732529\n",
      "Cost : 0.024278050288558006\n",
      "Cost : 0.055014967918395996\n",
      "Cost : 0.004599479027092457\n",
      "정확도 : 0.9911\n"
     ]
    }
   ],
   "source": [
    "#### MNIST with CNN\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 1. Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# 2. placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "keep_rate = tf.placeholder(dtype=tf.float32) # dropout 비율\n",
    "\n",
    "# 3. Convolution Layer\n",
    "# 3.1 Convolution Layer 1\n",
    "#     입력데이터의 형태를 Convolution할 수 있도록 4차배열로\n",
    "#     reshape (None,784) => \n",
    "X_img = tf.reshape(X, shape=[-1,28,28,1])\n",
    "#     Filter를 생성\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "#     Convolution\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "#     ReLU\n",
    "L1 = tf.nn.relu(L1)\n",
    "#     MAX Pooling\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], \n",
    "                    strides=[1,2,2,1], padding=\"SAME\")\n",
    "# 3.2 Convolution Layer 2\n",
    "#     Filter, Convolution, ReLU\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=64, \n",
    "                      kernel_size=[3,3], padding=\"SAME\",\n",
    "                      strides=1, activation=tf.nn.relu)\n",
    "#     MAX Pooling\n",
    "L2 = tf.layers.max_pooling2d(inputs=L2, pool_size=[2,2],\n",
    "                            padding=\"SAME\", strides=2)\n",
    "##### Convolution Layer 끝\n",
    "\n",
    "\n",
    "# 4. FC ( Neural Network )\n",
    "L2 = tf.reshape(L2, shape=[-1,7*7*64])\n",
    "\n",
    "# 5. Weight & bias\n",
    "W2 = tf.get_variable(\"weight2\", shape=[7*7*64,256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W2) + b2)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_rate)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[256,256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([256]), name=\"bias3\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W3) + b3)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob=keep_rate)\n",
    "\n",
    "W4 = tf.get_variable(\"weight4\", shape=[256,10],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([10]), name=\"bias4\")\n",
    "\n",
    "# Hypothesis\n",
    "H = tf.matmul(layer2,W4) + b4\n",
    "\n",
    "# Cost Function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H,\n",
    "                                                                labels=Y))\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 10\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x,\n",
    "                                                       Y:batch_y,\n",
    "                                                       keep_rate:0.5})\n",
    "    print(\"Cost : {}\".format(cost_val))\n",
    "\n",
    "# accuracy \n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct,dtype=tf.float32))\n",
    "\n",
    "result_sum = 0;\n",
    "### accuracy 측정을 위해서 batch처리\n",
    "num_of_iter = int(mnist.test.num_examples/batch_size)\n",
    "\n",
    "for i in range(num_of_iter):\n",
    "    batch_x, batch_y = mnist.test.next_batch(batch_size)\n",
    "    correct_num = sess.run(accuracy, feed_dict={X:batch_x,\n",
    "                                                Y:batch_y,\n",
    "                                                keep_rate:1})\n",
    "    result_sum += correct_num\n",
    "print(\"정확도 : {}\".format(result_sum/10000))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
